# Generate Unit Tests

I need help creating comprehensive unit tests following industry best practices and test-driven development principles. Please analyze the code and generate high-quality unit tests that ensure robust test coverage and maintainability.


***Analysis Requirements:***
 
1. Code Analysis:
   - Identify public interfaces and methods
   - Map dependencies and external interactions
   - Identify edge cases and boundary conditions
   - Analyze error handling paths
   - Review business logic complexity
   - Document assumptions and constraints
   - Identify state management patterns
   - List security considerations

2. Test Strategy:
   - Define test scope and objectives
   - Identify critical test scenarios
   - Plan mock/stub requirements
   - Design test data strategy
   - Define test isolation approach
   - Plan parameterized tests
   - Consider performance implications
   - Establish coverage targets

***Test Categories to Include:***

1. Happy Path Tests:
   - Normal operation scenarios
   - Expected input variations
   - Standard workflow validation
   - Success case coverage
   - Expected output validation
   - State transitions
   - Performance baselines
   - Integration points

2. Error Handling Tests:
   - Invalid inputs
   - Null/undefined scenarios
   - Boundary conditions
   - Exception handling
   - Timeout scenarios
   - Resource exhaustion
   - Network failures
   - Database errors

3. Edge Case Tests:
   - Minimum/maximum values
   - Empty collections
   - Large data sets
   - Special characters
   - Date boundaries
   - Numeric precision
   - Unicode handling
   - Concurrent access

4. Security Tests:
   - Input validation
   - Authorization checks
   - Authentication flows
   - Data sanitization
   - Access control
   - Secure configuration
   - Audit logging
   - Session handling

***Implementation Requirements:***
 
1. Test Structure:
   - Follow AAA pattern (Arrange-Act-Assert)
   - Clear test method naming
   - Descriptive test documentation
   - Logical test grouping
   - Independent test cases
   - Shared setup handling
   - Cleanup procedures
   - Resource management
 
2. Mocking Strategy:
   - External dependency isolation
   - Mock object configuration
   - Stub response definition
   - Verification patterns
   - Mock lifecycle management
   - Integration points
   - State simulation
   - Behavior verification
 
3. Assertion Patterns:
   - State verification
   - Behavior verification
   - Exception validation
   - Collection assertions
   - Object equality checks
   - Numeric precision handling
   - Timing validations
   - Order verification
 
4. Test Data Management:
   - Test data factories
   - Data builders
   - Fixture management
   - Database setup
   - Test isolation
   - Data cleanup
   - Seed data handling
   - Version control
 
***Best Practices:***
 
1. Code Quality:
   - DRY principle in tests
   - Single responsibility
   - Clear naming conventions
   - Consistent formatting
   - Proper documentation
   - Code organization
   - Maintainable structure
   - Readability focus
 
2. Performance Considerations:
   - Fast execution
   - Resource cleanup
   - Parallel execution
   - Test isolation
   - Minimal dependencies
   - Efficient setup/teardown
   - Caching strategies
   - Memory management
 
3. Maintainability:
   - Modular test design
   - Reusable components
   - Clear documentation
   - Version control
   - Dependency management
   - Configuration handling
   - Upgrade paths
   - Migration strategies
 
IMPORTANT: Format Response
1. Provide test implementation in standard Git diff format
2. Include test coverage metrics and analysis
3. Document any assumptions or prerequisites
4. Note potential improvements or recommendations
5. Include examples of test data and mock configurations


If you need any additional information about the code or its dependencies, please let me know.

import numpy
from _typeshed import Incomplete
from pyspark import RDD, SparkContext
from pyspark.mllib._typing import VectorLike
from pyspark.mllib.linalg import Vector
from pyspark.mllib.regression import LabeledPoint, LinearModel, StreamingLinearAlgorithm
from pyspark.mllib.util import Loader, Saveable
from pyspark.streaming.dstream import DStream
from typing import overload

__all__ = ['LogisticRegressionModel', 'LogisticRegressionWithSGD', 'LogisticRegressionWithLBFGS', 'SVMModel', 'SVMWithSGD', 'NaiveBayesModel', 'NaiveBayes', 'StreamingLogisticRegressionWithSGD']

class LinearClassificationModel(LinearModel):
    def __init__(self, weights: Vector, intercept: float) -> None: ...
    def setThreshold(self, value: float) -> None: ...
    @property
    def threshold(self) -> float | None: ...
    def clearThreshold(self) -> None: ...
    @overload
    def predict(self, test: VectorLike) -> int | float: ...
    @overload
    def predict(self, test: RDD['VectorLike']) -> RDD[int | float]: ...

class LogisticRegressionModel(LinearClassificationModel):
    def __init__(self, weights: Vector, intercept: float, numFeatures: int, numClasses: int) -> None: ...
    @property
    def numFeatures(self) -> int: ...
    @property
    def numClasses(self) -> int: ...
    @overload
    def predict(self, x: VectorLike) -> int | float: ...
    @overload
    def predict(self, x: RDD['VectorLike']) -> RDD[int | float]: ...
    def save(self, sc: SparkContext, path: str) -> None: ...
    @classmethod
    def load(cls, sc: SparkContext, path: str) -> LogisticRegressionModel: ...

class LogisticRegressionWithSGD:
    @classmethod
    def train(cls, data: RDD[LabeledPoint], iterations: int = 100, step: float = 1.0, miniBatchFraction: float = 1.0, initialWeights: VectorLike | None = None, regParam: float = 0.01, regType: str = 'l2', intercept: bool = False, validateData: bool = True, convergenceTol: float = 0.001) -> LogisticRegressionModel: ...

class LogisticRegressionWithLBFGS:
    @classmethod
    def train(cls, data: RDD[LabeledPoint], iterations: int = 100, initialWeights: VectorLike | None = None, regParam: float = 0.0, regType: str = 'l2', intercept: bool = False, corrections: int = 10, tolerance: float = 1e-06, validateData: bool = True, numClasses: int = 2) -> LogisticRegressionModel: ...

class SVMModel(LinearClassificationModel):
    def __init__(self, weights: Vector, intercept: float) -> None: ...
    @overload
    def predict(self, x: VectorLike) -> int | float: ...
    @overload
    def predict(self, x: RDD['VectorLike']) -> RDD[int | float]: ...
    def save(self, sc: SparkContext, path: str) -> None: ...
    @classmethod
    def load(cls, sc: SparkContext, path: str) -> SVMModel: ...

class SVMWithSGD:
    @classmethod
    def train(cls, data: RDD[LabeledPoint], iterations: int = 100, step: float = 1.0, regParam: float = 0.01, miniBatchFraction: float = 1.0, initialWeights: VectorLike | None = None, regType: str = 'l2', intercept: bool = False, validateData: bool = True, convergenceTol: float = 0.001) -> SVMModel: ...

class NaiveBayesModel(Saveable, Loader['NaiveBayesModel']):
    labels: Incomplete
    pi: Incomplete
    theta: Incomplete
    def __init__(self, labels: numpy.ndarray, pi: numpy.ndarray, theta: numpy.ndarray) -> None: ...
    @overload
    def predict(self, x: VectorLike) -> numpy.float64: ...
    @overload
    def predict(self, x: RDD['VectorLike']) -> RDD[numpy.float64]: ...
    def save(self, sc: SparkContext, path: str) -> None: ...
    @classmethod
    def load(cls, sc: SparkContext, path: str) -> NaiveBayesModel: ...

class NaiveBayes:
    @classmethod
    def train(cls, data: RDD[LabeledPoint], lambda_: float = 1.0) -> NaiveBayesModel: ...

class StreamingLogisticRegressionWithSGD(StreamingLinearAlgorithm):
    stepSize: Incomplete
    numIterations: Incomplete
    regParam: Incomplete
    miniBatchFraction: Incomplete
    convergenceTol: Incomplete
    def __init__(self, stepSize: float = 0.1, numIterations: int = 50, miniBatchFraction: float = 1.0, regParam: float = 0.0, convergenceTol: float = 0.001) -> None: ...
    def setInitialWeights(self, initialWeights: VectorLike) -> StreamingLogisticRegressionWithSGD: ...
    def trainOn(self, dstream: DStream[LabeledPoint]) -> None: ...

import abc
import grpc
from _typeshed import Incomplete
from functools import cached_property as cached_property
from pyspark.sql.connect.utils import check_dependencies as check_dependencies
from typing import BinaryIO, Iterable

JAR_PREFIX: str
PYFILE_PREFIX: str
ARCHIVE_PREFIX: str
FILE_PREFIX: str
FORWARD_TO_FS_PREFIX: str
CACHE_PREFIX: str

class LocalData(metaclass=abc.ABCMeta):
    @cached_property
    @abc.abstractmethod
    def stream(self) -> BinaryIO: ...
    @cached_property
    @abc.abstractmethod
    def size(self) -> int: ...

class LocalFile(LocalData):
    path: Incomplete
    def __init__(self, path: str) -> None: ...
    @cached_property
    def size(self) -> int: ...
    @cached_property
    def stream(self) -> BinaryIO: ...

class InMemory(LocalData):
    blob: Incomplete
    def __init__(self, blob: bytes) -> None: ...
    @cached_property
    def size(self) -> int: ...
    @cached_property
    def stream(self) -> BinaryIO: ...

class Artifact:
    path: Incomplete
    storage: Incomplete
    def __init__(self, path: str, storage: LocalData) -> None: ...
    @cached_property
    def size(self) -> int: ...

def new_jar_artifact(file_name: str, storage: LocalData) -> Artifact: ...
def new_pyfile_artifact(file_name: str, storage: LocalData) -> Artifact: ...
def new_archive_artifact(file_name: str, storage: LocalData) -> Artifact: ...
def new_file_artifact(file_name: str, storage: LocalData) -> Artifact: ...
def new_cache_artifact(id: str, storage: LocalData) -> Artifact: ...

class ArtifactManager:
    CHUNK_SIZE: int
    def __init__(self, user_id: str | None, session_id: str, channel: grpc.Channel, metadata: Iterable[tuple[str, str]]) -> None: ...
    def add_artifacts(self, *path: str, pyfile: bool, archive: bool, file: bool) -> None: ...
    def is_cached_artifact(self, hash: str) -> bool: ...
    def cache_artifact(self, blob: bytes) -> str: ...

from py4j.java_gateway import JavaObject
from pyspark import RDD
from pyspark.context import SparkContext
from pyspark.storagelevel import StorageLevel
from pyspark.streaming.dstream import DStream
from pyspark.streaming.listener import StreamingListener
from typing import Any, Callable, TypeVar

__all__ = ['StreamingContext']

T = TypeVar('T')

class StreamingContext:
    def __init__(self, sparkContext: SparkContext, batchDuration: int | None = None, jssc: JavaObject | None = None) -> None: ...
    @classmethod
    def getOrCreate(cls, checkpointPath: str, setupFunc: Callable[[], 'StreamingContext']) -> StreamingContext: ...
    @classmethod
    def getActive(cls) -> StreamingContext | None: ...
    @classmethod
    def getActiveOrCreate(cls, checkpointPath: str, setupFunc: Callable[[], 'StreamingContext']) -> StreamingContext: ...
    @property
    def sparkContext(self) -> SparkContext: ...
    def start(self) -> None: ...
    def awaitTermination(self, timeout: int | None = None) -> None: ...
    def awaitTerminationOrTimeout(self, timeout: int) -> None: ...
    def stop(self, stopSparkContext: bool = True, stopGraceFully: bool = False) -> None: ...
    def remember(self, duration: int) -> None: ...
    def checkpoint(self, directory: str) -> None: ...
    def socketTextStream(self, hostname: str, port: int, storageLevel: StorageLevel = ...) -> DStream[str]: ...
    def textFileStream(self, directory: str) -> DStream[str]: ...
    def binaryRecordsStream(self, directory: str, recordLength: int) -> DStream[bytes]: ...
    def queueStream(self, rdds: list[RDD[T]], oneAtATime: bool = True, default: RDD[T] | None = None) -> DStream[T]: ...
    def transform(self, dstreams: list['DStream[Any]'], transformFunc: Callable[..., RDD[T]]) -> DStream[T]: ...
    def union(self, *dstreams: DStream[T]) -> DStream[T]: ...
    def addStreamingListener(self, streamingListener: StreamingListener) -> None: ...

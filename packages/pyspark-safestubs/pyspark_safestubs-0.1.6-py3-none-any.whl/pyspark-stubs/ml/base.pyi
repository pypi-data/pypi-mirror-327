import abc
from _typeshed import Incomplete
from abc import ABCMeta, abstractmethod
from pyspark import since as since
from pyspark.ml._typing import ParamMap as ParamMap
from pyspark.ml.common import inherit_doc as inherit_doc
from pyspark.ml.param import P as P
from pyspark.ml.param.shared import HasFeaturesCol as HasFeaturesCol, HasInputCol as HasInputCol, HasLabelCol as HasLabelCol, HasOutputCol as HasOutputCol, HasPredictionCol as HasPredictionCol, Params as Params
from pyspark.sql.dataframe import DataFrame as DataFrame
from pyspark.sql.functions import udf as udf
from pyspark.sql.types import DataType as DataType, StructField as StructField, StructType as StructType
from typing import Any, Callable, Generic, Iterator, Sequence, TypeVar, overload

T = TypeVar('T')
M = TypeVar('M', bound='Transformer')

class _FitMultipleIterator(Generic[M]):
    fitSingleModel: Incomplete
    numModel: Incomplete
    counter: int
    lock: Incomplete
    def __init__(self, fitSingleModel: Callable[[int], M], numModels: int) -> None: ...
    def __iter__(self) -> Iterator[tuple[int, M]]: ...
    def __next__(self) -> tuple[int, M]: ...
    def next(self) -> tuple[int, M]: ...

class Estimator(Params, Generic[M], metaclass=ABCMeta):
    def fitMultiple(self, dataset: DataFrame, paramMaps: Sequence['ParamMap']) -> Iterator[tuple[int, M]]: ...
    @overload
    def fit(self, dataset: DataFrame, params: ParamMap | None = ...) -> M: ...
    @overload
    def fit(self, dataset: DataFrame, params: list['ParamMap'] | tuple['ParamMap']) -> list[M]: ...

class Transformer(Params, metaclass=ABCMeta):
    def transform(self, dataset: DataFrame, params: ParamMap | None = None) -> DataFrame: ...

class Model(Transformer, metaclass=ABCMeta): ...

class UnaryTransformer(HasInputCol, HasOutputCol, Transformer, metaclass=abc.ABCMeta):
    def setInputCol(self, value: str) -> P: ...
    def setOutputCol(self, value: str) -> P: ...
    @abstractmethod
    def createTransformFunc(self) -> Callable[..., Any]: ...
    @abstractmethod
    def outputDataType(self) -> DataType: ...
    @abstractmethod
    def validateInputType(self, inputType: DataType) -> None: ...
    def transformSchema(self, schema: StructType) -> StructType: ...

class _PredictorParams(HasLabelCol, HasFeaturesCol, HasPredictionCol): ...

class Predictor(Estimator[M], _PredictorParams, metaclass=ABCMeta):
    def setLabelCol(self, value: str) -> P: ...
    def setFeaturesCol(self, value: str) -> P: ...
    def setPredictionCol(self, value: str) -> P: ...

class PredictionModel(Model, _PredictorParams, Generic[T], metaclass=ABCMeta):
    def setFeaturesCol(self, value: str) -> P: ...
    def setPredictionCol(self, value: str) -> P: ...
    @property
    @abstractmethod
    def numFeatures(self) -> int: ...
    @abstractmethod
    def predict(self, value: T) -> float: ...

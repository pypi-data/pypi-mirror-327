import datetime
from decimal import Decimal
from typing import Any, Callable, Generic, Iterator, Literal, TypeVar, Union, overload

from _typeshed import Incomplete
from py4j.java_gateway import JavaObject
from pyspark._typing import PrimitiveType
from pyspark.pandas.frame import DataFrame as PandasOnSparkDataFrame
from pyspark.rdd import RDD
from pyspark.sql._typing import ColumnOrName, LiteralType, OptionalPrimitiveType
from pyspark.sql.column import Column
from pyspark.sql.context import SQLContext
from pyspark.sql.group import GroupedData
from pyspark.sql.observation import Observation
from pyspark.sql.pandas.conversion import PandasConversionMixin
from pyspark.sql.pandas.map_ops import PandasMapOpsMixin
from pyspark.sql.readwriter import DataFrameWriter, DataFrameWriterV2
from pyspark.sql.session import SparkSession
from pyspark.sql.streaming import DataStreamWriter
from pyspark.sql.types import Row, StructType
from pyspark.storagelevel import StorageLevel
from typing_extensions import LiteralString

__all__ = ["DataFrame", "DataFrameNaFunctions", "DataFrameStatFunctions"]

T = TypeVar("T", bound=LiteralString)
TAlias = TypeVar("TAlias", bound=LiteralString)
T2 = TypeVar("T2", bound=LiteralString)
In = TypeVar("In", bound=LiteralString)
Out = TypeVar("Out", bound=LiteralString)
InOther = TypeVar("InOther", bound=LiteralString)
OutOther = TypeVar("OutOther", bound=LiteralString)
OutOther2 = TypeVar("OutOther2", bound=LiteralString)
OutLit = TypeVar("OutLit", bound=LiteralString)
TSource = TypeVar("TSource", bound=LiteralString)
TResult = TypeVar("TResult", bound=LiteralString)

DecimalLiteral = Decimal
DateTimeLiteral = Union[datetime.datetime, datetime.date]

class _JoinContext(Generic[T, T2]):
    @overload
    def select(
        self,
        *cols: Column[Union[T, T2, Literal["lit"]], OutOther],
    ) -> DataFrame[OutOther]: ...
    @overload
    def select(
        self,
        cols: list[Column[Union[T, T2, Literal["lit"]], OutOther]],
    ) -> DataFrame[OutOther]: ...

class DataFrame(PandasMapOpsMixin, PandasConversionMixin, Generic[T]):
    is_cached: bool
    def __init__(self, jdf: JavaObject, sql_ctx: SQLContext | SparkSession) -> None: ...
    @property
    def sql_ctx(self) -> SQLContext: ...
    @property
    def sparkSession(self) -> SparkSession: ...
    @property
    def rdd(self) -> RDD[Row]: ...
    @property
    def na(self) -> DataFrameNaFunctions[T]: ...
    @property
    def stat(self) -> DataFrameStatFunctions[T]: ...
    def toJSON(self, use_unicode: bool = True) -> RDD[str]: ...
    def registerTempTable(self, name: str) -> None: ...
    def createTempView(self, name: str) -> None: ...
    def createOrReplaceTempView(self, name: str) -> None: ...
    def createGlobalTempView(self, name: str) -> None: ...
    def createOrReplaceGlobalTempView(self, name: str) -> None: ...
    @property
    def write(self) -> DataFrameWriter: ...
    @property
    def writeStream(self) -> DataStreamWriter: ...
    @property
    def schema(self) -> StructType: ...
    def printSchema(self, level: int | None = None) -> None: ...
    def explain(
        self, extended: bool | str | None = None, mode: str | None = None
    ) -> None: ...
    def exceptAll(self, other: DataFrame[T]) -> DataFrame[T]: ...
    def isLocal(self) -> bool: ...
    @property
    def isStreaming(self) -> bool: ...
    def isEmpty(self) -> bool: ...
    def show(
        self, n: int = 20, truncate: bool | int = True, vertical: bool = False
    ) -> None: ...
    def checkpoint(self, eager: bool = True) -> DataFrame[T]: ...
    def localCheckpoint(self, eager: bool = True) -> DataFrame[T]: ...
    def withWatermark(self, eventTime: str, delayThreshold: str) -> DataFrame[T]: ...
    def hint(
        self, name: str, *parameters: PrimitiveType | list["PrimitiveType"]
    ) -> DataFrame[T]: ...
    def count(self) -> int: ...
    def collect(self) -> list[Row]: ...
    def toLocalIterator(self, prefetchPartitions: bool = False) -> Iterator[Row]: ...
    def limit(self, num: int) -> DataFrame[T]: ...
    def offset(self, num: int) -> DataFrame[T]: ...
    def take(self, num: int) -> list[Row]: ...
    def tail(self, num: int) -> list[Row]: ...
    def foreach(self, f: Callable[[Row], None]) -> None: ...
    def foreachPartition(self, f: Callable[[Iterator[Row]], None]) -> None: ...
    def cache(self) -> DataFrame[T]: ...
    def persist(self, storageLevel: StorageLevel = ...) -> DataFrame[T]: ...
    @property
    def storageLevel(self) -> StorageLevel: ...
    def unpersist(self, blocking: bool = False) -> DataFrame[T]: ...
    def coalesce(self, numPartitions: int) -> DataFrame[T]: ...
    def repartition(
        self, numPartitions: int, *cols: ColumnOrName[T, LiteralString]
    ) -> DataFrame[T]: ...
    def repartitionByRange(
        self, numPartitions: int, *cols: ColumnOrName[T, LiteralString]
    ) -> DataFrame[T]: ...
    def distinct(self) -> DataFrame[T]: ...
    @overload
    def sample(self, fraction: float, seed: int | None = ...) -> DataFrame[T]: ...
    @overload
    def sample(
        self, withReplacement: bool | None, fraction: float, seed: int | None = ...
    ) -> DataFrame[T]: ...
    def sampleBy(
        self,
        col: ColumnOrName[T, T],
        fractions: dict[Any, float],
        seed: int | None = None,
    ) -> DataFrame[T]: ...
    def randomSplit(
        self, weights: list[float], seed: int | None = None
    ) -> list["DataFrame[T]"]: ...
    @property
    def dtypes(self) -> list[tuple[str, str]]: ...
    @property
    def columns(self) -> list[Column[T, T]]: ...
    def colRegex(self, colName: str) -> Column[T, T]: ...
    def to(self, schema: StructType) -> DataFrame[T]: ...
    def alias(self, alias: str) -> DataFrame[T]: ...
    def crossJoin(self, other: DataFrame[T2]) -> DataFrame[Union[T, T2]]: ...
    def join(
        self,
        other: DataFrame[T2],
        on: Column[Union[T, T2], LiteralString] | None = None,
        how: str | None = None,
    ) -> _JoinContext[T, T2]: ...
    def sortWithinPartitions(
        self, *cols: str | Column[T, T] | list[str | Column[T, T]], **kwargs: Any
    ) -> DataFrame[T]: ...
    def sort(
        self, *cols: str | Column[T, T] | list[str | Column[T, T]], **kwargs: Any
    ) -> DataFrame[T]: ...
    orderBy = sort
    def describe(self, *cols: str | list[str]) -> DataFrame[T]: ...
    def summary(self, *statistics: str) -> DataFrame[T]: ...
    @overload
    def head(self) -> Row | None: ...
    @overload
    def head(self, n: int) -> list[Row]: ...
    def first(self) -> Row | None: ...
    @overload
    def __getitem__(self, item: int) -> Column[LiteralString, LiteralString]: ...
    @overload
    def __getitem__(self, item: T) -> Column[T, T]: ...
    @overload
    def __getitem__(
        self, item: Column[T, T] | list[Column[T, T]] | tuple[Column[T, T], ...]
    ) -> DataFrame[T]: ...
    def __getattr__(self, name: T) -> Column[T, T]: ...
    def __dir__(self) -> list[str]: ...
    @overload
    def select(self, /, __cols: list[Column[T, TResult]]) -> DataFrame[TResult]: ...
    @overload
    def select(
        self, *cols: Column[Union[T, Literal["lit"]], OutOther]
    ) -> DataFrame[OutOther]: ...
    @overload
    def select(self, /, __cols: list[T]) -> DataFrame[T]: ...
    @overload
    def selectExpr(self, *expr: str) -> DataFrame[T]: ...
    @overload
    def selectExpr(self, *expr: list[str]) -> DataFrame[T]: ...
    def filter(self, condition: ColumnOrName[InOther, OutOther]) -> DataFrame[T]: ...
    @overload
    def groupBy(self, *cols: ColumnOrName[In, Out]) -> GroupedData[T, In]: ...
    @overload
    def groupBy(
        self, /, __cols: list[Column[In, Out]] | list[str]
    ) -> GroupedData[T, Out]: ...
    @overload
    def rollup(self, *cols: ColumnOrName[In, Out]) -> GroupedData[T, Out]: ...
    @overload
    def rollup(
        self, /, __cols: list[Column[In, Out]] | list[str]
    ) -> GroupedData[T, Out]: ...
    @overload
    def cube(self, *cols: ColumnOrName[In, Out]) -> GroupedData[T, Out]: ...
    @overload
    def cube(
        self, /, __cols: list[Column[In, Out]] | list[str]
    ) -> GroupedData[T, Out]: ...
    def unpivot(
        self,
        ids: ColumnOrName[T, T]
        | list[ColumnOrName[T, T]]
        | tuple[ColumnOrName[T, T], ...],
        values: ColumnOrName[T, T]
        | list[ColumnOrName[T, T]]
        | tuple[ColumnOrName[T, T], ...]
        | None,
        variableColumnName: str,
        valueColumnName: str,
    ) -> DataFrame[T]: ...
    def melt(
        self,
        ids: ColumnOrName[T, T]
        | list[ColumnOrName[T, T]]
        | tuple[ColumnOrName[T, T], ...],
        values: ColumnOrName[T, T]
        | list[ColumnOrName[T, T]]
        | tuple[ColumnOrName[T, T], ...]
        | None,
        variableColumnName: str,
        valueColumnName: str,
    ) -> DataFrame[T]: ...
    def agg(self, *exprs: Column[Any, Out]) -> DataFrame[Out]: ...
    def observe(
        self, observation: Observation | str, *exprs: Column[Any, Out]
    ) -> DataFrame[Out]: ...
    def union(self, other: DataFrame[T2]) -> DataFrame[Union[T, T2]]: ...
    def unionAll(self, other: DataFrame[T2]) -> DataFrame[Union[T, T2]]: ...
    def unionByName(
        self, other: DataFrame[T2], allowMissingColumns: bool = False
    ) -> DataFrame[Union[T, T2]]: ...
    def intersect(self, other: DataFrame[T2]) -> DataFrame[Union[T, T2]]: ...
    def intersectAll(self, other: DataFrame[T2]) -> DataFrame[Union[T, T2]]: ...
    def subtract(self, other: DataFrame[T2]) -> DataFrame[Union[T, T2]]: ...
    def dropDuplicates(self, subset: list[T] | None = None) -> DataFrame[T]: ...
    def dropDuplicatesWithinWatermark(
        self, subset: list[str] | None = None
    ) -> DataFrame[T]: ...
    def dropna(
        self,
        how: str = "any",
        thresh: int | None = None,
        subset: str | tuple[str, ...] | list[str] | None = None,
    ) -> DataFrame[T]: ...
    @overload
    def fillna(
        self, value: LiteralType, subset: str | tuple[str, ...] | list[str] | None = ...
    ) -> DataFrame[T]: ...
    @overload
    def fillna(self, value: dict[str, "LiteralType"]) -> DataFrame[T]: ...
    @overload
    def replace(
        self,
        to_replace: LiteralType,
        value: OptionalPrimitiveType,
        subset: list[str] | None = ...,
    ) -> DataFrame[T]: ...
    @overload
    def replace(
        self,
        to_replace: list["LiteralType"],
        value: list["OptionalPrimitiveType"],
        subset: list[str] | None = ...,
    ) -> DataFrame[T]: ...
    @overload
    def replace(
        self,
        to_replace: dict["LiteralType", "OptionalPrimitiveType"],
        subset: list[str] | None = ...,
    ) -> DataFrame[T]: ...
    @overload
    def replace(
        self,
        to_replace: list["LiteralType"],
        value: OptionalPrimitiveType,
        subset: list[str] | None = ...,
    ) -> DataFrame[T]: ...
    @overload
    def approxQuantile(
        self,
        col: str,
        probabilities: list[float] | tuple[float],
        relativeError: float,
    ) -> list[float]: ...
    @overload
    def approxQuantile(
        self,
        col: list[str] | tuple[str],
        probabilities: list[float] | tuple[float],
        relativeError: float,
    ) -> list[list[float]]: ...
    def corr(self, col1: str, col2: str, method: str | None = None) -> float: ...
    def cov(self, col1: str, col2: str) -> float: ...
    def crosstab(self, col1: str, col2: str) -> DataFrame[T]: ...
    def freqItems(
        self, cols: list[str] | tuple[str], support: float | None = None
    ) -> DataFrame[T]: ...
    def withColumns(
        self, *colsMap: dict[T2, Column[T, Out]]
    ) -> DataFrame[Union[T, T2]]: ...
    def withColumn(
        self, colName: T2, col: Column[Union[T, Literal["lit", "expr"]], Out]
    ) -> "DataFrame[Union[T, T2]]": ...
    def withColumnRenamed(self, existing: T, new: T2) -> DataFrame[Union[T, T2]]: ...
    def withColumnsRenamed(self, colsMap: dict[str, str]) -> DataFrame[T]: ...
    def withMetadata(
        self, columnName: str, metadata: dict[str, Any]
    ) -> DataFrame[T]: ...
    @overload
    def drop(self, cols: ColumnOrName[T, T]) -> DataFrame[T]: ...
    @overload
    def drop(self, *cols: LiteralString) -> DataFrame[T]: ...
    def toDF(self, *cols: str) -> DataFrame[T]: ...
    def transform(
        self, func: Callable[..., "DataFrame[T]"], *args: Any, **kwargs: Any
    ) -> DataFrame[T]: ...
    def sameSemantics(self, other: DataFrame[T]) -> bool: ...
    def semanticHash(self) -> int: ...
    def inputFiles(self) -> list[str]: ...
    where: Incomplete
    groupby: Incomplete
    drop_duplicates: Incomplete
    def writeTo(self, table: str) -> DataFrameWriterV2: ...
    def to_pandas_on_spark(
        self, index_col: str | list[str] | None = None
    ) -> PandasOnSparkDataFrame[T]: ...
    def pandas_api(
        self, index_col: str | list[str] | None = None
    ) -> PandasOnSparkDataFrame[T]: ...
    def to_koalas(
        self, index_col: str | list[str] | None = None
    ) -> PandasOnSparkDataFrame[T]: ...

class DataFrameNaFunctions(Generic[T]):
    df: DataFrame[T]
    def __init__(self, df: DataFrame[T]) -> None: ...
    def drop(
        self,
        how: str = "any",
        thresh: int | None = None,
        subset: str | tuple[str, ...] | list[str] | None = None,
    ) -> DataFrame[T]: ...
    @overload
    def fill(
        self, value: LiteralType, subset: list[str] | None = ...
    ) -> DataFrame[T]: ...
    @overload
    def fill(self, value: dict[str, "LiteralType"]) -> DataFrame[T]: ...
    @overload
    def replace(
        self,
        to_replace: list["LiteralType"],
        value: list["OptionalPrimitiveType"],
        subset: list[str] | None = ...,
    ) -> DataFrame[T]: ...
    @overload
    def replace(
        self,
        to_replace: dict["LiteralType", "OptionalPrimitiveType"],
        subset: list[str] | None = ...,
    ) -> DataFrame[T]: ...
    @overload
    def replace(
        self,
        to_replace: list["LiteralType"],
        value: OptionalPrimitiveType,
        subset: list[str] | None = ...,
    ) -> DataFrame[T]: ...

class DataFrameStatFunctions(Generic[T]):
    df: DataFrame[T]
    def __init__(self, df: DataFrame[T]) -> None: ...
    @overload
    def approxQuantile(
        self, col: str, probabilities: list[float] | tuple[float], relativeError: float
    ) -> list[float]: ...
    @overload
    def approxQuantile(
        self,
        col: list[str] | tuple[str],
        probabilities: list[float] | tuple[float],
        relativeError: float,
    ) -> list[list[float]]: ...
    def corr(self, col1: str, col2: str, method: str | None = None) -> float: ...
    def cov(self, col1: str, col2: str) -> float: ...
    def crosstab(self, col1: str, col2: str) -> DataFrame[T]: ...
    def freqItems(
        self, cols: list[str], support: float | None = None
    ) -> DataFrame[T]: ...
    def sampleBy(
        self, col: str, fractions: dict[Any, float], seed: int | None = None
    ) -> DataFrame[T]: ...

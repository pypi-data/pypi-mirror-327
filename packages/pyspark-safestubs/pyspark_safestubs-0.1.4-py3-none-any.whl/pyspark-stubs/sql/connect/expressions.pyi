import pyspark.sql.connect.proto as proto
from _typeshed import Incomplete
from pyspark.errors import PySparkTypeError as PySparkTypeError, PySparkValueError as PySparkValueError
from pyspark.serializers import CloudPickleSerializer as CloudPickleSerializer
from pyspark.sql.connect.client import SparkConnectClient as SparkConnectClient
from pyspark.sql.connect.types import JVM_BYTE_MAX as JVM_BYTE_MAX, JVM_BYTE_MIN as JVM_BYTE_MIN, JVM_INT_MAX as JVM_INT_MAX, JVM_INT_MIN as JVM_INT_MIN, JVM_LONG_MAX as JVM_LONG_MAX, JVM_LONG_MIN as JVM_LONG_MIN, JVM_SHORT_MAX as JVM_SHORT_MAX, JVM_SHORT_MIN as JVM_SHORT_MIN, UnparsedDataType as UnparsedDataType, proto_schema_to_pyspark_data_type as proto_schema_to_pyspark_data_type, pyspark_types_to_proto_types as pyspark_types_to_proto_types
from pyspark.sql.connect.utils import check_dependencies as check_dependencies
from pyspark.sql.connect.window import WindowSpec as WindowSpec
from pyspark.sql.types import ArrayType as ArrayType, BinaryType as BinaryType, BooleanType as BooleanType, ByteType as ByteType, DataType as DataType, DateType as DateType, DayTimeIntervalType as DayTimeIntervalType, DecimalType as DecimalType, DoubleType as DoubleType, FloatType as FloatType, IntegerType as IntegerType, LongType as LongType, NullType as NullType, ShortType as ShortType, StringType as StringType, TimestampNTZType as TimestampNTZType, TimestampType as TimestampType
from pyspark.sql.utils import is_timestamp_ntz_preferred as is_timestamp_ntz_preferred
from typing import Any, Callable, Sequence

class Expression:
    def __init__(self) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...
    def alias(self, *alias: str, **kwargs: Any) -> ColumnAlias: ...
    def name(self) -> str: ...

class CaseWhen(Expression):
    def __init__(self, branches: Sequence[tuple[Expression, Expression]], else_value: Expression | None) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class ColumnAlias(Expression):
    def __init__(self, parent: Expression, alias: Sequence[str], metadata: Any) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class LiteralExpression(Expression):
    def __init__(self, value: Any, dataType: DataType) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class ColumnReference(Expression):
    def __init__(self, unparsed_identifier: str, plan_id: int | None = None) -> None: ...
    def name(self) -> str: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...
    def __eq__(self, other: Any) -> bool: ...

class UnresolvedStar(Expression):
    def __init__(self, unparsed_target: str | None) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...
    def __eq__(self, other: Any) -> bool: ...

class SQLExpression(Expression):
    def __init__(self, expr: str) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...
    def __eq__(self, other: Any) -> bool: ...

class SortOrder(Expression):
    def __init__(self, child: Expression, ascending: bool = True, nullsFirst: bool = True) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class UnresolvedFunction(Expression):
    def __init__(self, name: str, args: Sequence['Expression'], is_distinct: bool = False) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class PythonUDF:
    def __init__(self, output_type: DataType | str, eval_type: int, func: Callable[..., Any], python_ver: str) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.PythonUDF: ...

class JavaUDF:
    def __init__(self, class_name: str, output_type: DataType | str | None = None, aggregate: bool = False) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.JavaUDF: ...

class CommonInlineUserDefinedFunction(Expression):
    def __init__(self, function_name: str, function: PythonUDF | JavaUDF, deterministic: bool = False, arguments: Sequence[Expression] = []) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...
    def to_plan_udf(self, session: SparkConnectClient) -> proto.CommonInlineUserDefinedFunction: ...
    def to_plan_judf(self, session: SparkConnectClient) -> proto.CommonInlineUserDefinedFunction: ...

class WithField(Expression):
    def __init__(self, structExpr: Expression, fieldName: str, valueExpr: Expression) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class DropField(Expression):
    def __init__(self, structExpr: Expression, fieldName: str) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class UnresolvedExtractValue(Expression):
    def __init__(self, child: Expression, extraction: Expression) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class UnresolvedRegex(Expression):
    col_name: Incomplete
    def __init__(self, col_name: str, plan_id: int | None = None) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class CastExpression(Expression):
    def __init__(self, expr: Expression, data_type: DataType | str) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class UnresolvedNamedLambdaVariable(Expression):
    def __init__(self, name_parts: Sequence[str]) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...
    @staticmethod
    def fresh_var_name(name: str) -> str: ...

class LambdaFunction(Expression):
    def __init__(self, function: Expression, arguments: Sequence[UnresolvedNamedLambdaVariable]) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class WindowExpression(Expression):
    def __init__(self, windowFunction: Expression, windowSpec: WindowSpec) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class DistributedSequenceID(Expression):
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

class CallFunction(Expression):
    def __init__(self, name: str, args: Sequence['Expression']) -> None: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...

from _typeshed import Incomplete
from abc import ABCMeta, abstractmethod
from pyspark import SparkContext
from pyspark.ml import Estimator, Model, PredictionModel, Predictor
from pyspark.ml._typing import P, ParamMap
from pyspark.ml.base import _PredictorParams
from pyspark.ml.linalg import Matrix, Vector
from pyspark.ml.param.shared import HasAggregationDepth, HasBlockSize, HasElasticNetParam, HasFitIntercept, HasMaxBlockSizeInMB, HasMaxIter, HasParallelism, HasProbabilityCol, HasRawPredictionCol, HasRegParam, HasSeed, HasSolver, HasStandardization, HasStepSize, HasThreshold, HasThresholds, HasTol, HasWeightCol, Param
from pyspark.ml.regression import DecisionTreeRegressionModel, _FactorizationMachinesParams
from pyspark.ml.tree import _DecisionTreeModel, _DecisionTreeParams, _GBTParams, _HasVarianceImpurity, _RandomForestParams, _TreeClassifierParams, _TreeEnsembleModel
from pyspark.ml.util import HasTrainingSummary, JavaMLReadable, JavaMLWritable, MLReadable, MLReader, MLWritable, MLWriter
from pyspark.ml.wrapper import JavaPredictionModel, JavaPredictor, JavaWrapper
from pyspark.sql import DataFrame
from typing import Any, Generic, TypeVar, overload

__all__ = ['LinearSVC', 'LinearSVCModel', 'LinearSVCSummary', 'LinearSVCTrainingSummary', 'LogisticRegression', 'LogisticRegressionModel', 'LogisticRegressionSummary', 'LogisticRegressionTrainingSummary', 'BinaryLogisticRegressionSummary', 'BinaryLogisticRegressionTrainingSummary', 'DecisionTreeClassifier', 'DecisionTreeClassificationModel', 'GBTClassifier', 'GBTClassificationModel', 'RandomForestClassifier', 'RandomForestClassificationModel', 'RandomForestClassificationSummary', 'RandomForestClassificationTrainingSummary', 'BinaryRandomForestClassificationSummary', 'BinaryRandomForestClassificationTrainingSummary', 'NaiveBayes', 'NaiveBayesModel', 'MultilayerPerceptronClassifier', 'MultilayerPerceptronClassificationModel', 'MultilayerPerceptronClassificationSummary', 'MultilayerPerceptronClassificationTrainingSummary', 'OneVsRest', 'OneVsRestModel', 'FMClassifier', 'FMClassificationModel', 'FMClassificationSummary', 'FMClassificationTrainingSummary']

T = TypeVar('T')
JPM = TypeVar('JPM', bound=JavaPredictionModel)
CM = TypeVar('CM', bound='ClassificationModel')

class _ClassifierParams(HasRawPredictionCol, _PredictorParams): ...

class Classifier(Predictor[CM], _ClassifierParams, Generic[CM], metaclass=ABCMeta):
    def setRawPredictionCol(self, value: str) -> P: ...

class ClassificationModel(PredictionModel, _ClassifierParams, metaclass=ABCMeta):
    def setRawPredictionCol(self, value: str) -> P: ...
    @property
    @abstractmethod
    def numClasses(self) -> int: ...
    @abstractmethod
    def predictRaw(self, value: Vector) -> Vector: ...

class _ProbabilisticClassifierParams(HasProbabilityCol, HasThresholds, _ClassifierParams): ...

class ProbabilisticClassifier(Classifier, _ProbabilisticClassifierParams, metaclass=ABCMeta):
    def setProbabilityCol(self, value: str) -> P: ...
    def setThresholds(self, value: list[float]) -> P: ...

class ProbabilisticClassificationModel(ClassificationModel, _ProbabilisticClassifierParams, metaclass=ABCMeta):
    def setProbabilityCol(self, value: str) -> CM: ...
    def setThresholds(self, value: list[float]) -> CM: ...
    @abstractmethod
    def predictProbability(self, value: Vector) -> Vector: ...

class _JavaClassifier(Classifier, JavaPredictor[JPM], Generic[JPM], metaclass=ABCMeta):
    def setRawPredictionCol(self, value: str) -> P: ...

class _JavaClassificationModel(ClassificationModel, JavaPredictionModel[T]):
    @property
    def numClasses(self) -> int: ...
    def predictRaw(self, value: Vector) -> Vector: ...

class _JavaProbabilisticClassifier(ProbabilisticClassifier, _JavaClassifier[JPM], Generic[JPM], metaclass=ABCMeta): ...

class _JavaProbabilisticClassificationModel(ProbabilisticClassificationModel, _JavaClassificationModel[T]):
    def predictProbability(self, value: Vector) -> Vector: ...

class _ClassificationSummary(JavaWrapper):
    @property
    def predictions(self) -> DataFrame: ...
    @property
    def predictionCol(self) -> str: ...
    @property
    def labelCol(self) -> str: ...
    @property
    def weightCol(self) -> str: ...
    @property
    def labels(self) -> list[str]: ...
    @property
    def truePositiveRateByLabel(self) -> list[float]: ...
    @property
    def falsePositiveRateByLabel(self) -> list[float]: ...
    @property
    def precisionByLabel(self) -> list[float]: ...
    @property
    def recallByLabel(self) -> list[float]: ...
    def fMeasureByLabel(self, beta: float = 1.0) -> list[float]: ...
    @property
    def accuracy(self) -> float: ...
    @property
    def weightedTruePositiveRate(self) -> float: ...
    @property
    def weightedFalsePositiveRate(self) -> float: ...
    @property
    def weightedRecall(self) -> float: ...
    @property
    def weightedPrecision(self) -> float: ...
    def weightedFMeasure(self, beta: float = 1.0) -> float: ...

class _TrainingSummary(JavaWrapper):
    @property
    def objectiveHistory(self) -> list[float]: ...
    @property
    def totalIterations(self) -> int: ...

class _BinaryClassificationSummary(_ClassificationSummary):
    @property
    def scoreCol(self) -> str: ...
    @property
    def roc(self) -> DataFrame: ...
    @property
    def areaUnderROC(self) -> float: ...
    @property
    def pr(self) -> DataFrame: ...
    @property
    def fMeasureByThreshold(self) -> DataFrame: ...
    @property
    def precisionByThreshold(self) -> DataFrame: ...
    @property
    def recallByThreshold(self) -> DataFrame: ...

class _LinearSVCParams(_ClassifierParams, HasRegParam, HasMaxIter, HasFitIntercept, HasTol, HasStandardization, HasWeightCol, HasAggregationDepth, HasThreshold, HasMaxBlockSizeInMB):
    threshold: Param[float]
    def __init__(self, *args: Any) -> None: ...

class LinearSVC(_JavaClassifier['LinearSVCModel'], _LinearSVCParams, JavaMLWritable, JavaMLReadable['LinearSVC']):
    def __init__(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxIter: int = 100, regParam: float = 0.0, tol: float = 1e-06, rawPredictionCol: str = 'rawPrediction', fitIntercept: bool = True, standardization: bool = True, threshold: float = 0.0, weightCol: str | None = None, aggregationDepth: int = 2, maxBlockSizeInMB: float = 0.0) -> None: ...
    def setParams(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxIter: int = 100, regParam: float = 0.0, tol: float = 1e-06, rawPredictionCol: str = 'rawPrediction', fitIntercept: bool = True, standardization: bool = True, threshold: float = 0.0, weightCol: str | None = None, aggregationDepth: int = 2, maxBlockSizeInMB: float = 0.0) -> LinearSVC: ...
    def setMaxIter(self, value: int) -> LinearSVC: ...
    def setRegParam(self, value: float) -> LinearSVC: ...
    def setTol(self, value: float) -> LinearSVC: ...
    def setFitIntercept(self, value: bool) -> LinearSVC: ...
    def setStandardization(self, value: bool) -> LinearSVC: ...
    def setThreshold(self, value: float) -> LinearSVC: ...
    def setWeightCol(self, value: str) -> LinearSVC: ...
    def setAggregationDepth(self, value: int) -> LinearSVC: ...
    def setMaxBlockSizeInMB(self, value: float) -> LinearSVC: ...

class LinearSVCModel(_JavaClassificationModel[Vector], _LinearSVCParams, JavaMLWritable, JavaMLReadable['LinearSVCModel'], HasTrainingSummary['LinearSVCTrainingSummary']):
    def setThreshold(self, value: float) -> LinearSVCModel: ...
    @property
    def coefficients(self) -> Vector: ...
    @property
    def intercept(self) -> float: ...
    def summary(self) -> LinearSVCTrainingSummary: ...
    def evaluate(self, dataset: DataFrame) -> LinearSVCSummary: ...

class LinearSVCSummary(_BinaryClassificationSummary): ...
class LinearSVCTrainingSummary(LinearSVCSummary, _TrainingSummary): ...

class _LogisticRegressionParams(_ProbabilisticClassifierParams, HasRegParam, HasElasticNetParam, HasMaxIter, HasFitIntercept, HasTol, HasStandardization, HasWeightCol, HasAggregationDepth, HasThreshold, HasMaxBlockSizeInMB):
    threshold: Param[float]
    family: Param[str]
    lowerBoundsOnCoefficients: Param[Matrix]
    upperBoundsOnCoefficients: Param[Matrix]
    lowerBoundsOnIntercepts: Param[Vector]
    upperBoundsOnIntercepts: Param[Vector]
    def __init__(self, *args: Any) -> None: ...
    def setThreshold(self, value: float) -> P: ...
    def getThreshold(self) -> float: ...
    def setThresholds(self, value: list[float]) -> P: ...
    def getThresholds(self) -> list[float]: ...
    def getFamily(self) -> str: ...
    def getLowerBoundsOnCoefficients(self) -> Matrix: ...
    def getUpperBoundsOnCoefficients(self) -> Matrix: ...
    def getLowerBoundsOnIntercepts(self) -> Vector: ...
    def getUpperBoundsOnIntercepts(self) -> Vector: ...

class LogisticRegression(_JavaProbabilisticClassifier['LogisticRegressionModel'], _LogisticRegressionParams, JavaMLWritable, JavaMLReadable['LogisticRegression']):
    @overload
    def __init__(self, *, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., maxIter: int = ..., regParam: float = ..., elasticNetParam: float = ..., tol: float = ..., fitIntercept: bool = ..., threshold: float = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., standardization: bool = ..., weightCol: str | None = ..., aggregationDepth: int = ..., family: str = ..., lowerBoundsOnCoefficients: Matrix | None = ..., upperBoundsOnCoefficients: Matrix | None = ..., lowerBoundsOnIntercepts: Vector | None = ..., upperBoundsOnIntercepts: Vector | None = ..., maxBlockSizeInMB: float = ...) -> None: ...
    @overload
    def __init__(self, *, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., maxIter: int = ..., regParam: float = ..., elasticNetParam: float = ..., tol: float = ..., fitIntercept: bool = ..., thresholds: list[float] | None = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., standardization: bool = ..., weightCol: str | None = ..., aggregationDepth: int = ..., family: str = ..., lowerBoundsOnCoefficients: Matrix | None = ..., upperBoundsOnCoefficients: Matrix | None = ..., lowerBoundsOnIntercepts: Vector | None = ..., upperBoundsOnIntercepts: Vector | None = ..., maxBlockSizeInMB: float = ...) -> None: ...
    @overload
    def setParams(self, *, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., maxIter: int = ..., regParam: float = ..., elasticNetParam: float = ..., tol: float = ..., fitIntercept: bool = ..., threshold: float = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., standardization: bool = ..., weightCol: str | None = ..., aggregationDepth: int = ..., family: str = ..., lowerBoundsOnCoefficients: Matrix | None = ..., upperBoundsOnCoefficients: Matrix | None = ..., lowerBoundsOnIntercepts: Vector | None = ..., upperBoundsOnIntercepts: Vector | None = ..., maxBlockSizeInMB: float = ...) -> LogisticRegression: ...
    @overload
    def setParams(self, *, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., maxIter: int = ..., regParam: float = ..., elasticNetParam: float = ..., tol: float = ..., fitIntercept: bool = ..., thresholds: list[float] | None = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., standardization: bool = ..., weightCol: str | None = ..., aggregationDepth: int = ..., family: str = ..., lowerBoundsOnCoefficients: Matrix | None = ..., upperBoundsOnCoefficients: Matrix | None = ..., lowerBoundsOnIntercepts: Vector | None = ..., upperBoundsOnIntercepts: Vector | None = ..., maxBlockSizeInMB: float = ...) -> LogisticRegression: ...
    def setFamily(self, value: str) -> LogisticRegression: ...
    def setLowerBoundsOnCoefficients(self, value: Matrix) -> LogisticRegression: ...
    def setUpperBoundsOnCoefficients(self, value: Matrix) -> LogisticRegression: ...
    def setLowerBoundsOnIntercepts(self, value: Vector) -> LogisticRegression: ...
    def setUpperBoundsOnIntercepts(self, value: Vector) -> LogisticRegression: ...
    def setMaxIter(self, value: int) -> LogisticRegression: ...
    def setRegParam(self, value: float) -> LogisticRegression: ...
    def setTol(self, value: float) -> LogisticRegression: ...
    def setElasticNetParam(self, value: float) -> LogisticRegression: ...
    def setFitIntercept(self, value: bool) -> LogisticRegression: ...
    def setStandardization(self, value: bool) -> LogisticRegression: ...
    def setWeightCol(self, value: str) -> LogisticRegression: ...
    def setAggregationDepth(self, value: int) -> LogisticRegression: ...
    def setMaxBlockSizeInMB(self, value: float) -> LogisticRegression: ...

class LogisticRegressionModel(_JavaProbabilisticClassificationModel[Vector], _LogisticRegressionParams, JavaMLWritable, JavaMLReadable['LogisticRegressionModel'], HasTrainingSummary['LogisticRegressionTrainingSummary']):
    @property
    def coefficients(self) -> Vector: ...
    @property
    def intercept(self) -> float: ...
    @property
    def coefficientMatrix(self) -> Matrix: ...
    @property
    def interceptVector(self) -> Vector: ...
    @property
    def summary(self) -> LogisticRegressionTrainingSummary: ...
    def evaluate(self, dataset: DataFrame) -> LogisticRegressionSummary: ...

class LogisticRegressionSummary(_ClassificationSummary):
    @property
    def probabilityCol(self) -> str: ...
    @property
    def featuresCol(self) -> str: ...

class LogisticRegressionTrainingSummary(LogisticRegressionSummary, _TrainingSummary): ...
class BinaryLogisticRegressionSummary(_BinaryClassificationSummary, LogisticRegressionSummary): ...
class BinaryLogisticRegressionTrainingSummary(BinaryLogisticRegressionSummary, LogisticRegressionTrainingSummary): ...

class _DecisionTreeClassifierParams(_DecisionTreeParams, _TreeClassifierParams):
    def __init__(self, *args: Any) -> None: ...

class DecisionTreeClassifier(_JavaProbabilisticClassifier['DecisionTreeClassificationModel'], _DecisionTreeClassifierParams, JavaMLWritable, JavaMLReadable['DecisionTreeClassifier']):
    def __init__(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', probabilityCol: str = 'probability', rawPredictionCol: str = 'rawPrediction', maxDepth: int = 5, maxBins: int = 32, minInstancesPerNode: int = 1, minInfoGain: float = 0.0, maxMemoryInMB: int = 256, cacheNodeIds: bool = False, checkpointInterval: int = 10, impurity: str = 'gini', seed: int | None = None, weightCol: str | None = None, leafCol: str = '', minWeightFractionPerNode: float = 0.0) -> None: ...
    def setParams(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', probabilityCol: str = 'probability', rawPredictionCol: str = 'rawPrediction', maxDepth: int = 5, maxBins: int = 32, minInstancesPerNode: int = 1, minInfoGain: float = 0.0, maxMemoryInMB: int = 256, cacheNodeIds: bool = False, checkpointInterval: int = 10, impurity: str = 'gini', seed: int | None = None, weightCol: str | None = None, leafCol: str = '', minWeightFractionPerNode: float = 0.0) -> DecisionTreeClassifier: ...
    def setMaxDepth(self, value: int) -> DecisionTreeClassifier: ...
    def setMaxBins(self, value: int) -> DecisionTreeClassifier: ...
    def setMinInstancesPerNode(self, value: int) -> DecisionTreeClassifier: ...
    def setMinWeightFractionPerNode(self, value: float) -> DecisionTreeClassifier: ...
    def setMinInfoGain(self, value: float) -> DecisionTreeClassifier: ...
    def setMaxMemoryInMB(self, value: int) -> DecisionTreeClassifier: ...
    def setCacheNodeIds(self, value: bool) -> DecisionTreeClassifier: ...
    def setImpurity(self, value: str) -> DecisionTreeClassifier: ...
    def setCheckpointInterval(self, value: int) -> DecisionTreeClassifier: ...
    def setSeed(self, value: int) -> DecisionTreeClassifier: ...
    def setWeightCol(self, value: str) -> DecisionTreeClassifier: ...

class DecisionTreeClassificationModel(_DecisionTreeModel, _JavaProbabilisticClassificationModel[Vector], _DecisionTreeClassifierParams, JavaMLWritable, JavaMLReadable['DecisionTreeClassificationModel']):
    @property
    def featureImportances(self) -> Vector: ...

class _RandomForestClassifierParams(_RandomForestParams, _TreeClassifierParams):
    def __init__(self, *args: Any) -> None: ...

class RandomForestClassifier(_JavaProbabilisticClassifier['RandomForestClassificationModel'], _RandomForestClassifierParams, JavaMLWritable, JavaMLReadable['RandomForestClassifier']):
    def __init__(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', probabilityCol: str = 'probability', rawPredictionCol: str = 'rawPrediction', maxDepth: int = 5, maxBins: int = 32, minInstancesPerNode: int = 1, minInfoGain: float = 0.0, maxMemoryInMB: int = 256, cacheNodeIds: bool = False, checkpointInterval: int = 10, impurity: str = 'gini', numTrees: int = 20, featureSubsetStrategy: str = 'auto', seed: int | None = None, subsamplingRate: float = 1.0, leafCol: str = '', minWeightFractionPerNode: float = 0.0, weightCol: str | None = None, bootstrap: bool | None = True) -> None: ...
    def setParams(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', probabilityCol: str = 'probability', rawPredictionCol: str = 'rawPrediction', maxDepth: int = 5, maxBins: int = 32, minInstancesPerNode: int = 1, minInfoGain: float = 0.0, maxMemoryInMB: int = 256, cacheNodeIds: bool = False, checkpointInterval: int = 10, impurity: str = 'gini', numTrees: int = 20, featureSubsetStrategy: str = 'auto', seed: int | None = None, subsamplingRate: float = 1.0, leafCol: str = '', minWeightFractionPerNode: float = 0.0, weightCol: str | None = None, bootstrap: bool | None = True) -> RandomForestClassifier: ...
    def setMaxDepth(self, value: int) -> RandomForestClassifier: ...
    def setMaxBins(self, value: int) -> RandomForestClassifier: ...
    def setMinInstancesPerNode(self, value: int) -> RandomForestClassifier: ...
    def setMinInfoGain(self, value: float) -> RandomForestClassifier: ...
    def setMaxMemoryInMB(self, value: int) -> RandomForestClassifier: ...
    def setCacheNodeIds(self, value: bool) -> RandomForestClassifier: ...
    def setImpurity(self, value: str) -> RandomForestClassifier: ...
    def setNumTrees(self, value: int) -> RandomForestClassifier: ...
    def setBootstrap(self, value: bool) -> RandomForestClassifier: ...
    def setSubsamplingRate(self, value: float) -> RandomForestClassifier: ...
    def setFeatureSubsetStrategy(self, value: str) -> RandomForestClassifier: ...
    def setSeed(self, value: int) -> RandomForestClassifier: ...
    def setCheckpointInterval(self, value: int) -> RandomForestClassifier: ...
    def setWeightCol(self, value: str) -> RandomForestClassifier: ...
    def setMinWeightFractionPerNode(self, value: float) -> RandomForestClassifier: ...

class RandomForestClassificationModel(_TreeEnsembleModel, _JavaProbabilisticClassificationModel[Vector], _RandomForestClassifierParams, JavaMLWritable, JavaMLReadable['RandomForestClassificationModel'], HasTrainingSummary['RandomForestClassificationTrainingSummary']):
    @property
    def featureImportances(self) -> Vector: ...
    @property
    def trees(self) -> list[DecisionTreeClassificationModel]: ...
    @property
    def summary(self) -> RandomForestClassificationTrainingSummary: ...
    def evaluate(self, dataset: DataFrame) -> BinaryRandomForestClassificationSummary | RandomForestClassificationSummary: ...

class RandomForestClassificationSummary(_ClassificationSummary): ...
class RandomForestClassificationTrainingSummary(RandomForestClassificationSummary, _TrainingSummary): ...
class BinaryRandomForestClassificationSummary(_BinaryClassificationSummary): ...
class BinaryRandomForestClassificationTrainingSummary(BinaryRandomForestClassificationSummary, RandomForestClassificationTrainingSummary): ...

class _GBTClassifierParams(_GBTParams, _HasVarianceImpurity):
    supportedLossTypes: list[str]
    lossType: Param[str]
    def __init__(self, *args: Any) -> None: ...
    def getLossType(self) -> str: ...

class GBTClassifier(_JavaProbabilisticClassifier['GBTClassificationModel'], _GBTClassifierParams, JavaMLWritable, JavaMLReadable['GBTClassifier']):
    def __init__(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxDepth: int = 5, maxBins: int = 32, minInstancesPerNode: int = 1, minInfoGain: float = 0.0, maxMemoryInMB: int = 256, cacheNodeIds: bool = False, checkpointInterval: int = 10, lossType: str = 'logistic', maxIter: int = 20, stepSize: float = 0.1, seed: int | None = None, subsamplingRate: float = 1.0, impurity: str = 'variance', featureSubsetStrategy: str = 'all', validationTol: float = 0.01, validationIndicatorCol: str | None = None, leafCol: str = '', minWeightFractionPerNode: float = 0.0, weightCol: str | None = None) -> None: ...
    def setParams(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxDepth: int = 5, maxBins: int = 32, minInstancesPerNode: int = 1, minInfoGain: float = 0.0, maxMemoryInMB: int = 256, cacheNodeIds: bool = False, checkpointInterval: int = 10, lossType: str = 'logistic', maxIter: int = 20, stepSize: float = 0.1, seed: int | None = None, subsamplingRate: float = 1.0, impurity: str = 'variance', featureSubsetStrategy: str = 'all', validationTol: float = 0.01, validationIndicatorCol: str | None = None, leafCol: str = '', minWeightFractionPerNode: float = 0.0, weightCol: str | None = None) -> GBTClassifier: ...
    def setMaxDepth(self, value: int) -> GBTClassifier: ...
    def setMaxBins(self, value: int) -> GBTClassifier: ...
    def setMinInstancesPerNode(self, value: int) -> GBTClassifier: ...
    def setMinInfoGain(self, value: float) -> GBTClassifier: ...
    def setMaxMemoryInMB(self, value: int) -> GBTClassifier: ...
    def setCacheNodeIds(self, value: bool) -> GBTClassifier: ...
    def setImpurity(self, value: str) -> GBTClassifier: ...
    def setLossType(self, value: str) -> GBTClassifier: ...
    def setSubsamplingRate(self, value: float) -> GBTClassifier: ...
    def setFeatureSubsetStrategy(self, value: str) -> GBTClassifier: ...
    def setValidationIndicatorCol(self, value: str) -> GBTClassifier: ...
    def setMaxIter(self, value: int) -> GBTClassifier: ...
    def setCheckpointInterval(self, value: int) -> GBTClassifier: ...
    def setSeed(self, value: int) -> GBTClassifier: ...
    def setStepSize(self, value: int) -> GBTClassifier: ...
    def setWeightCol(self, value: str) -> GBTClassifier: ...
    def setMinWeightFractionPerNode(self, value: float) -> GBTClassifier: ...

class GBTClassificationModel(_TreeEnsembleModel, _JavaProbabilisticClassificationModel[Vector], _GBTClassifierParams, JavaMLWritable, JavaMLReadable['GBTClassificationModel']):
    @property
    def featureImportances(self) -> Vector: ...
    @property
    def trees(self) -> list[DecisionTreeRegressionModel]: ...
    def evaluateEachIteration(self, dataset: DataFrame) -> list[float]: ...

class _NaiveBayesParams(_PredictorParams, HasWeightCol):
    smoothing: Param[float]
    modelType: Param[str]
    def __init__(self, *args: Any) -> None: ...
    def getSmoothing(self) -> float: ...
    def getModelType(self) -> str: ...

class NaiveBayes(_JavaProbabilisticClassifier['NaiveBayesModel'], _NaiveBayesParams, HasThresholds, HasWeightCol, JavaMLWritable, JavaMLReadable['NaiveBayes']):
    def __init__(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', probabilityCol: str = 'probability', rawPredictionCol: str = 'rawPrediction', smoothing: float = 1.0, modelType: str = 'multinomial', thresholds: list[float] | None = None, weightCol: str | None = None) -> None: ...
    def setParams(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', probabilityCol: str = 'probability', rawPredictionCol: str = 'rawPrediction', smoothing: float = 1.0, modelType: str = 'multinomial', thresholds: list[float] | None = None, weightCol: str | None = None) -> NaiveBayes: ...
    def setSmoothing(self, value: float) -> NaiveBayes: ...
    def setModelType(self, value: str) -> NaiveBayes: ...
    def setWeightCol(self, value: str) -> NaiveBayes: ...

class NaiveBayesModel(_JavaProbabilisticClassificationModel[Vector], _NaiveBayesParams, JavaMLWritable, JavaMLReadable['NaiveBayesModel']):
    @property
    def pi(self) -> Vector: ...
    @property
    def theta(self) -> Matrix: ...
    @property
    def sigma(self) -> Matrix: ...

class _MultilayerPerceptronParams(_ProbabilisticClassifierParams, HasSeed, HasMaxIter, HasTol, HasStepSize, HasSolver, HasBlockSize):
    layers: Param[list[int]]
    solver: Param[str]
    initialWeights: Param[Vector]
    def __init__(self, *args: Any) -> None: ...
    def getLayers(self) -> list[int]: ...
    def getInitialWeights(self) -> Vector: ...

class MultilayerPerceptronClassifier(_JavaProbabilisticClassifier['MultilayerPerceptronClassificationModel'], _MultilayerPerceptronParams, JavaMLWritable, JavaMLReadable['MultilayerPerceptronClassifier']):
    def __init__(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxIter: int = 100, tol: float = 1e-06, seed: int | None = None, layers: list[int] | None = None, blockSize: int = 128, stepSize: float = 0.03, solver: str = 'l-bfgs', initialWeights: Vector | None = None, probabilityCol: str = 'probability', rawPredictionCol: str = 'rawPrediction') -> None: ...
    def setParams(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxIter: int = 100, tol: float = 1e-06, seed: int | None = None, layers: list[int] | None = None, blockSize: int = 128, stepSize: float = 0.03, solver: str = 'l-bfgs', initialWeights: Vector | None = None, probabilityCol: str = 'probability', rawPredictionCol: str = 'rawPrediction') -> MultilayerPerceptronClassifier: ...
    def setLayers(self, value: list[int]) -> MultilayerPerceptronClassifier: ...
    def setBlockSize(self, value: int) -> MultilayerPerceptronClassifier: ...
    def setInitialWeights(self, value: Vector) -> MultilayerPerceptronClassifier: ...
    def setMaxIter(self, value: int) -> MultilayerPerceptronClassifier: ...
    def setSeed(self, value: int) -> MultilayerPerceptronClassifier: ...
    def setTol(self, value: float) -> MultilayerPerceptronClassifier: ...
    def setStepSize(self, value: float) -> MultilayerPerceptronClassifier: ...
    def setSolver(self, value: str) -> MultilayerPerceptronClassifier: ...

class MultilayerPerceptronClassificationModel(_JavaProbabilisticClassificationModel[Vector], _MultilayerPerceptronParams, JavaMLWritable, JavaMLReadable['MultilayerPerceptronClassificationModel'], HasTrainingSummary['MultilayerPerceptronClassificationTrainingSummary']):
    @property
    def weights(self) -> Vector: ...
    def summary(self) -> MultilayerPerceptronClassificationTrainingSummary: ...
    def evaluate(self, dataset: DataFrame) -> MultilayerPerceptronClassificationSummary: ...

class MultilayerPerceptronClassificationSummary(_ClassificationSummary): ...
class MultilayerPerceptronClassificationTrainingSummary(MultilayerPerceptronClassificationSummary, _TrainingSummary): ...

class _OneVsRestParams(_ClassifierParams, HasWeightCol):
    classifier: Param[Classifier]
    def getClassifier(self) -> Classifier: ...

class OneVsRest(Estimator['OneVsRestModel'], _OneVsRestParams, HasParallelism, MLReadable['OneVsRest'], MLWritable, Generic[CM]):
    def __init__(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', rawPredictionCol: str = 'rawPrediction', classifier: Classifier[CM] | None = None, weightCol: str | None = None, parallelism: int = 1) -> None: ...
    def setParams(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', rawPredictionCol: str = 'rawPrediction', classifier: Classifier[CM] | None = None, weightCol: str | None = None, parallelism: int = 1) -> OneVsRest: ...
    def setClassifier(self, value: Classifier[CM]) -> OneVsRest: ...
    def setLabelCol(self, value: str) -> OneVsRest: ...
    def setFeaturesCol(self, value: str) -> OneVsRest: ...
    def setPredictionCol(self, value: str) -> OneVsRest: ...
    def setRawPredictionCol(self, value: str) -> OneVsRest: ...
    def setWeightCol(self, value: str) -> OneVsRest: ...
    def setParallelism(self, value: int) -> OneVsRest: ...
    def copy(self, extra: ParamMap | None = None) -> OneVsRest: ...
    @classmethod
    def read(cls) -> OneVsRestReader: ...
    def write(self) -> MLWriter: ...

class _OneVsRestSharedReadWrite:
    @staticmethod
    def saveImpl(instance: OneVsRest | OneVsRestModel, sc: SparkContext, path: str, extraMetadata: dict[str, Any] | None = None) -> None: ...
    @staticmethod
    def loadClassifier(path: str, sc: SparkContext) -> OneVsRest | OneVsRestModel: ...
    @staticmethod
    def validateParams(instance: OneVsRest | OneVsRestModel) -> None: ...

class OneVsRestReader(MLReader[OneVsRest]):
    cls: Incomplete
    def __init__(self, cls: type[OneVsRest]) -> None: ...
    def load(self, path: str) -> OneVsRest: ...

class OneVsRestWriter(MLWriter):
    instance: Incomplete
    def __init__(self, instance: OneVsRest) -> None: ...
    def saveImpl(self, path: str) -> None: ...

class OneVsRestModel(Model, _OneVsRestParams, MLReadable['OneVsRestModel'], MLWritable):
    def setFeaturesCol(self, value: str) -> OneVsRestModel: ...
    def setPredictionCol(self, value: str) -> OneVsRestModel: ...
    def setRawPredictionCol(self, value: str) -> OneVsRestModel: ...
    models: Incomplete
    def __init__(self, models: list[ClassificationModel]) -> None: ...
    def copy(self, extra: ParamMap | None = None) -> OneVsRestModel: ...
    @classmethod
    def read(cls) -> OneVsRestModelReader: ...
    def write(self) -> MLWriter: ...

class OneVsRestModelReader(MLReader[OneVsRestModel]):
    cls: Incomplete
    def __init__(self, cls: type[OneVsRestModel]) -> None: ...
    def load(self, path: str) -> OneVsRestModel: ...

class OneVsRestModelWriter(MLWriter):
    instance: Incomplete
    def __init__(self, instance: OneVsRestModel) -> None: ...
    def saveImpl(self, path: str) -> None: ...

class FMClassifier(_JavaProbabilisticClassifier['FMClassificationModel'], _FactorizationMachinesParams, JavaMLWritable, JavaMLReadable['FMClassifier']):
    def __init__(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', probabilityCol: str = 'probability', rawPredictionCol: str = 'rawPrediction', factorSize: int = 8, fitIntercept: bool = True, fitLinear: bool = True, regParam: float = 0.0, miniBatchFraction: float = 1.0, initStd: float = 0.01, maxIter: int = 100, stepSize: float = 1.0, tol: float = 1e-06, solver: str = 'adamW', thresholds: list[float] | None = None, seed: int | None = None) -> None: ...
    def setParams(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', probabilityCol: str = 'probability', rawPredictionCol: str = 'rawPrediction', factorSize: int = 8, fitIntercept: bool = True, fitLinear: bool = True, regParam: float = 0.0, miniBatchFraction: float = 1.0, initStd: float = 0.01, maxIter: int = 100, stepSize: float = 1.0, tol: float = 1e-06, solver: str = 'adamW', thresholds: list[float] | None = None, seed: int | None = None) -> FMClassifier: ...
    def setFactorSize(self, value: int) -> FMClassifier: ...
    def setFitLinear(self, value: bool) -> FMClassifier: ...
    def setMiniBatchFraction(self, value: float) -> FMClassifier: ...
    def setInitStd(self, value: float) -> FMClassifier: ...
    def setMaxIter(self, value: int) -> FMClassifier: ...
    def setStepSize(self, value: float) -> FMClassifier: ...
    def setTol(self, value: float) -> FMClassifier: ...
    def setSolver(self, value: str) -> FMClassifier: ...
    def setSeed(self, value: int) -> FMClassifier: ...
    def setFitIntercept(self, value: bool) -> FMClassifier: ...
    def setRegParam(self, value: float) -> FMClassifier: ...

class FMClassificationModel(_JavaProbabilisticClassificationModel[Vector], _FactorizationMachinesParams, JavaMLWritable, JavaMLReadable['FMClassificationModel'], HasTrainingSummary):
    @property
    def intercept(self) -> float: ...
    @property
    def linear(self) -> Vector: ...
    @property
    def factors(self) -> Matrix: ...
    def summary(self) -> FMClassificationTrainingSummary: ...
    def evaluate(self, dataset: DataFrame) -> FMClassificationSummary: ...

class FMClassificationSummary(_BinaryClassificationSummary): ...
class FMClassificationTrainingSummary(FMClassificationSummary, _TrainingSummary): ...

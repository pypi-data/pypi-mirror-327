from _typeshed import Incomplete
from py4j.java_gateway import JavaObject as JavaObject
from pyspark import SparkContext as SparkContext, keyword_only as keyword_only, since as since
from pyspark.ml._typing import ParamMap as ParamMap, PipelineStage as PipelineStage
from pyspark.ml.base import Estimator as Estimator, Model as Model, Transformer as Transformer
from pyspark.ml.common import inherit_doc as inherit_doc
from pyspark.ml.param import Param as Param, Params as Params
from pyspark.ml.util import DefaultParamsReader as DefaultParamsReader, DefaultParamsWriter as DefaultParamsWriter, JavaMLReadable as JavaMLReadable, JavaMLReader as JavaMLReader, JavaMLWritable as JavaMLWritable, JavaMLWriter as JavaMLWriter, MLReadable as MLReadable, MLReader as MLReader, MLWritable as MLWritable, MLWriter as MLWriter
from pyspark.ml.wrapper import JavaParams as JavaParams
from pyspark.sql.dataframe import DataFrame as DataFrame
from typing import Any

class Pipeline(Estimator['PipelineModel'], MLReadable['Pipeline'], MLWritable):
    stages: Param[list['PipelineStage']]
    def __init__(self, *, stages: list['PipelineStage'] | None = None) -> None: ...
    def setStages(self, value: list['PipelineStage']) -> Pipeline: ...
    def getStages(self) -> list['PipelineStage']: ...
    def setParams(self, *, stages: list['PipelineStage'] | None = None) -> Pipeline: ...
    def copy(self, extra: ParamMap | None = None) -> Pipeline: ...
    def write(self) -> MLWriter: ...
    @classmethod
    def read(cls) -> PipelineReader: ...

class PipelineWriter(MLWriter):
    instance: Incomplete
    def __init__(self, instance: Pipeline) -> None: ...
    def saveImpl(self, path: str) -> None: ...

class PipelineReader(MLReader[Pipeline]):
    cls: Incomplete
    def __init__(self, cls: type[Pipeline]) -> None: ...
    def load(self, path: str) -> Pipeline: ...

class PipelineModelWriter(MLWriter):
    instance: Incomplete
    def __init__(self, instance: PipelineModel) -> None: ...
    def saveImpl(self, path: str) -> None: ...

class PipelineModelReader(MLReader['PipelineModel']):
    cls: Incomplete
    def __init__(self, cls: type['PipelineModel']) -> None: ...
    def load(self, path: str) -> PipelineModel: ...

class PipelineModel(Model, MLReadable['PipelineModel'], MLWritable):
    stages: Incomplete
    def __init__(self, stages: list[Transformer]) -> None: ...
    def copy(self, extra: ParamMap | None = None) -> PipelineModel: ...
    def write(self) -> MLWriter: ...
    @classmethod
    def read(cls) -> PipelineModelReader: ...

class PipelineSharedReadWrite:
    @staticmethod
    def checkStagesForJava(stages: list['PipelineStage']) -> bool: ...
    @staticmethod
    def validateStages(stages: list['PipelineStage']) -> None: ...
    @staticmethod
    def saveImpl(instance: Pipeline | PipelineModel, stages: list['PipelineStage'], sc: SparkContext, path: str) -> None: ...
    @staticmethod
    def load(metadata: dict[str, Any], sc: SparkContext, path: str) -> tuple[str, list['PipelineStage']]: ...
    @staticmethod
    def getStagePath(stageUid: str, stageIdx: int, numStages: int, stagesDir: str) -> str: ...

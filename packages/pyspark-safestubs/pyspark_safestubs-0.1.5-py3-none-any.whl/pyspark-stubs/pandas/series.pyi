import datetime
import pandas as pd
from _typeshed import Incomplete
from collections.abc import Mapping
from pandas.tseries.frequencies import DateOffset as DateOffset
from pyspark import pandas as ps
from pyspark.pandas._typing import Axis as Axis, Dtype as Dtype, Label as Label, Name as Name, Scalar as Scalar, T as T
from pyspark.pandas.accessors import PandasOnSparkSeriesMethods as PandasOnSparkSeriesMethods
from pyspark.pandas.base import IndexOpsMixin as IndexOpsMixin
from pyspark.pandas.categorical import CategoricalAccessor as CategoricalAccessor
from pyspark.pandas.config import get_option as get_option
from pyspark.pandas.correlation import CORRELATION_CORR_OUTPUT_COLUMN as CORRELATION_CORR_OUTPUT_COLUMN, CORRELATION_COUNT_OUTPUT_COLUMN as CORRELATION_COUNT_OUTPUT_COLUMN, CORRELATION_VALUE_1_COLUMN as CORRELATION_VALUE_1_COLUMN, CORRELATION_VALUE_2_COLUMN as CORRELATION_VALUE_2_COLUMN, compute as compute
from pyspark.pandas.datetimes import DatetimeMethods as DatetimeMethods
from pyspark.pandas.exceptions import SparkPandasIndexingError as SparkPandasIndexingError
from pyspark.pandas.frame import DataFrame as DataFrame
from pyspark.pandas.generic import Frame as Frame
from pyspark.pandas.groupby import SeriesGroupBy as SeriesGroupBy
from pyspark.pandas.indexes import Index as Index
from pyspark.pandas.internal import DEFAULT_SERIES_NAME as DEFAULT_SERIES_NAME, InternalField as InternalField, InternalFrame as InternalFrame, NATURAL_ORDER_COLUMN_NAME as NATURAL_ORDER_COLUMN_NAME, SPARK_DEFAULT_INDEX_NAME as SPARK_DEFAULT_INDEX_NAME, SPARK_DEFAULT_SERIES_NAME as SPARK_DEFAULT_SERIES_NAME
from pyspark.pandas.missing.series import MissingPandasLikeSeries as MissingPandasLikeSeries
from pyspark.pandas.plot import PandasOnSparkPlotAccessor as PandasOnSparkPlotAccessor
from pyspark.pandas.resample import SeriesResampler as SeriesResampler
from pyspark.pandas.spark.accessors import SparkIndexOpsMethods as SparkIndexOpsMethods, SparkSeriesMethods as SparkSeriesMethods
from pyspark.pandas.strings import StringMethods as StringMethods
from pyspark.pandas.typedef import ScalarType as ScalarType, SeriesType as SeriesType, create_type_for_series_type as create_type_for_series_type, infer_return_type as infer_return_type, spark_type_to_pandas_dtype as spark_type_to_pandas_dtype
from pyspark.pandas.typedef.typehints import as_spark_type as as_spark_type
from pyspark.pandas.utils import SPARK_CONF_ARROW_ENABLED as SPARK_CONF_ARROW_ENABLED, combine_frames as combine_frames, is_name_like_tuple as is_name_like_tuple, is_name_like_value as is_name_like_value, log_advice as log_advice, name_like_string as name_like_string, same_anchor as same_anchor, scol_for as scol_for, sql_conf as sql_conf, validate_arguments_and_invoke_function as validate_arguments_and_invoke_function, validate_axis as validate_axis, validate_bool_kwarg as validate_bool_kwarg, verify_temp_column_name as verify_temp_column_name
from pyspark.sql import DataFrame as SparkDataFrame
from pyspark.sql._typing import ColumnOrName as ColumnOrName
from pyspark.sql.types import ArrayType as ArrayType, BooleanType as BooleanType, DecimalType as DecimalType, DoubleType as DoubleType, FloatType as FloatType, IntegerType as IntegerType, IntegralType as IntegralType, LongType as LongType, NumericType as NumericType, Row as Row, StructType as StructType, TimestampType as TimestampType
from pyspark.sql.utils import get_column_class as get_column_class, get_window_class as get_window_class
from pyspark.sql.window import Window as Window
from typing import Any, Callable, Generic, IO, Iterable, Sequence, overload

REPR_PATTERN: Incomplete
str_type = str

class Series(Frame, IndexOpsMixin, Generic[T]):
    def __init__(self, data: Incomplete | None = None, index: Incomplete | None = None, dtype: Incomplete | None = None, name: Incomplete | None = None, copy: bool = False, fastpath: bool = False) -> None: ...
    spark: SparkIndexOpsMethods
    @property
    def dtypes(self) -> Dtype: ...
    @property
    def axes(self) -> list['Index']: ...
    def add(self, other: Any, fill_value: int | str | float = None) -> Series: ...
    def radd(self, other: Any, fill_value: int | str | float = None) -> Series: ...
    def div(self, other: Any) -> Series: ...
    divide = div
    def rdiv(self, other: Any) -> Series: ...
    def truediv(self, other: Any) -> Series: ...
    def rtruediv(self, other: Any) -> Series: ...
    def mul(self, other: Any) -> Series: ...
    multiply = mul
    def rmul(self, other: Any) -> Series: ...
    def sub(self, other: Any) -> Series: ...
    subtract = sub
    def rsub(self, other: Any) -> Series: ...
    def mod(self, other: Any) -> Series: ...
    def rmod(self, other: Any) -> Series: ...
    def pow(self, other: Any) -> Series: ...
    def rpow(self, other: Any) -> Series: ...
    def floordiv(self, other: Any) -> Series: ...
    def rfloordiv(self, other: Any) -> Series: ...
    pandas_on_spark: Incomplete
    koalas: Incomplete
    def eq(self, other: Any) -> Series: ...
    equals = eq
    def gt(self, other: Any) -> Series: ...
    def ge(self, other: Any) -> Series: ...
    def lt(self, other: Any) -> Series: ...
    def le(self, other: Any) -> Series: ...
    def ne(self, other: Any) -> Series: ...
    def divmod(self, other: Any) -> tuple['Series', 'Series']: ...
    def rdivmod(self, other: Any) -> tuple['Series', 'Series']: ...
    def between(self, left: Any, right: Any, inclusive: bool | str = 'both') -> Series: ...
    def cov(self, other: Series, min_periods: int | None = None, ddof: int = 1) -> float: ...
    def map(self, arg: dict | Callable[[Any], Any] | pd.Series, na_action: str | None = None) -> Series: ...
    @property
    def shape(self) -> tuple[int]: ...
    @property
    def name(self) -> Name: ...
    @name.setter
    def name(self, name: Name) -> None: ...
    def rename(self, index: Name | Callable[[Any], Any] | None = None, **kwargs: Any) -> Series: ...
    def rename_axis(self, mapper: Any | None = None, index: Any | None = None, inplace: bool = False) -> Series | None: ...
    @property
    def index(self) -> ps.Index: ...
    @property
    def is_unique(self) -> bool: ...
    def reset_index(self, level: int | Name | Sequence[int | Name] | None = None, drop: bool = False, name: Name | None = None, inplace: bool = False) -> Series | DataFrame | None: ...
    def to_frame(self, name: Name | None = None) -> DataFrame: ...
    to_dataframe = to_frame
    def to_string(self, buf: IO[str] | None = None, na_rep: str = 'NaN', float_format: Callable[[float], str] | None = None, header: bool = True, index: bool = True, length: bool = False, dtype: bool = False, name: bool = False, max_rows: int | None = None) -> str | None: ...
    def to_clipboard(self, excel: bool = True, sep: str | None = None, **kwargs: Any) -> None: ...
    def to_dict(self, into: type = ...) -> Mapping: ...
    def to_latex(self, buf: IO[str] | None = None, columns: list[Name] | None = None, col_space: int | None = None, header: bool = True, index: bool = True, na_rep: str = 'NaN', formatters: list[Callable[[Any], str]] | dict[Name, Callable[[Any], str]] | None = None, float_format: Callable[[float], str] | None = None, sparsify: bool | None = None, index_names: bool = True, bold_rows: bool = False, column_format: str | None = None, longtable: bool | None = None, escape: bool | None = None, encoding: str | None = None, decimal: str = '.', multicolumn: bool | None = None, multicolumn_format: str | None = None, multirow: bool | None = None) -> str | None: ...
    def to_pandas(self) -> pd.Series: ...
    def to_list(self) -> list: ...
    tolist = to_list
    def duplicated(self, keep: bool | str = 'first') -> Series: ...
    def drop_duplicates(self, keep: bool | str = 'first', inplace: bool = False) -> Series | None: ...
    def reindex(self, index: Any | None = None, fill_value: Any | None = None) -> Series: ...
    def reindex_like(self, other: Series | DataFrame) -> Series: ...
    def fillna(self, value: Any | None = None, method: str | None = None, axis: Axis | None = None, inplace: bool = False, limit: int | None = None) -> Series | None: ...
    def interpolate(self, method: str = 'linear', limit: int | None = None, limit_direction: str | None = None, limit_area: str | None = None) -> Series: ...
    def dropna(self, axis: Axis = 0, inplace: bool = False, **kwargs: Any) -> Series | None: ...
    def clip(self, lower: float | int = None, upper: float | int = None, inplace: bool = False) -> Series: ...
    def drop(self, labels: Name | list[Name] | None = None, index: Name | list[Name] | None = None, columns: Name | list[Name] | None = None, level: int | None = None, inplace: bool = False) -> Series: ...
    def head(self, n: int = 5) -> Series: ...
    def last(self, offset: str | DateOffset) -> Series: ...
    def first(self, offset: str | DateOffset) -> Series: ...
    def unique(self) -> Series: ...
    def sort_values(self, ascending: bool = True, inplace: bool = False, na_position: str = 'last', ignore_index: bool = False) -> Series | None: ...
    def sort_index(self, axis: Axis = 0, level: int | list[int] | None = None, ascending: bool = True, inplace: bool = False, kind: str = None, na_position: str = 'last', ignore_index: bool = False) -> Series | None: ...
    def swaplevel(self, i: int | Name = -2, j: int | Name = -1, copy: bool = True) -> Series: ...
    def swapaxes(self, i: Axis, j: Axis, copy: bool = True) -> Series: ...
    def add_prefix(self, prefix: str) -> Series: ...
    def add_suffix(self, suffix: str) -> Series: ...
    def autocorr(self, lag: int = 1) -> float: ...
    def corr(self, other: Series, method: str = 'pearson', min_periods: int | None = None) -> float: ...
    def nsmallest(self, n: int = 5) -> Series: ...
    def nlargest(self, n: int = 5) -> Series: ...
    def append(self, to_append: Series, ignore_index: bool = False, verify_integrity: bool = False) -> Series: ...
    def sample(self, n: int | None = None, frac: float | None = None, replace: bool = False, random_state: int | None = None, ignore_index: bool = False) -> Series: ...
    def hist(self, bins: int = 10, **kwds): ...
    def apply(self, func: Callable, args: Sequence[Any] = (), **kwds: Any) -> Series: ...
    def aggregate(self, func: str | list[str]) -> Scalar | Series: ...
    agg = aggregate
    def transpose(self, *args: Any, **kwargs: Any) -> Series: ...
    T: Incomplete
    def transform(self, func: Callable | list[Callable], axis: Axis = 0, *args: Any, **kwargs: Any) -> Series | DataFrame: ...
    def round(self, decimals: int = 0) -> Series: ...
    def quantile(self, q: float | Iterable[float] = 0.5, accuracy: int = 10000) -> Scalar | Series: ...
    def rank(self, method: str = 'average', ascending: bool = True, numeric_only: bool | None = None) -> Series: ...
    def filter(self, items: Sequence[Any] | None = None, like: str | None = None, regex: str | None = None, axis: Axis | None = None) -> Series: ...
    def describe(self, percentiles: list[float] | None = None) -> Series: ...
    def diff(self, periods: int = 1) -> Series: ...
    def idxmax(self, skipna: bool = True) -> tuple | Any: ...
    def idxmin(self, skipna: bool = True) -> tuple | Any: ...
    def pop(self, item: Name) -> Series | Scalar: ...
    def copy(self, deep: bool = True) -> Series: ...
    def mode(self, dropna: bool = True) -> Series: ...
    def keys(self) -> ps.Index: ...
    def replace(self, to_replace: Any | list | tuple | dict | None = None, value: list | tuple | None = None, regex: str | bool = False) -> Series: ...
    def update(self, other: Series) -> None: ...
    def where(self, cond: Series, other: Any = ...) -> Series: ...
    def mask(self, cond: Series, other: Any = ...) -> Series: ...
    def xs(self, key: Name, level: int | None = None) -> Series: ...
    def pct_change(self, periods: int = 1) -> Series: ...
    def combine_first(self, other: Series) -> Series: ...
    def dot(self, other: Series | DataFrame) -> Scalar | Series: ...
    def __matmul__(self, other: Series | DataFrame) -> Scalar | Series: ...
    def repeat(self, repeats: int | Series) -> Series: ...
    def asof(self, where: Any | list) -> Scalar | Series: ...
    def mad(self) -> float: ...
    def unstack(self, level: int = -1) -> DataFrame: ...
    def item(self) -> Scalar: ...
    def items(self) -> Iterable[tuple[Name, Any]]: ...
    def iteritems(self) -> Iterable[tuple[Name, Any]]: ...
    def droplevel(self, level: int | Name | list[int | Name]) -> Series: ...
    def tail(self, n: int = 5) -> Series: ...
    def explode(self) -> Series: ...
    def argsort(self) -> Series: ...
    def argmax(self, axis: Axis = None, skipna: bool = True) -> int: ...
    def argmin(self, axis: Axis = None, skipna: bool = True) -> int: ...
    def compare(self, other: Series, keep_shape: bool = False, keep_equal: bool = False) -> DataFrame: ...
    def searchsorted(self, value: Any, side: str = 'left') -> int: ...
    def align(self, other: DataFrame | Series, join: str = 'outer', axis: Axis | None = None, copy: bool = True) -> tuple['Series', DataFrame | Series]: ...
    def between_time(self, start_time: datetime.time | str, end_time: datetime.time | str, include_start: bool = True, include_end: bool = True, axis: Axis = 0) -> Series: ...
    def at_time(self, time: datetime.time | str, asof: bool = False, axis: Axis = 0) -> Series: ...
    dt: Incomplete
    str: Incomplete
    cat: Incomplete
    plot: Incomplete
    def groupby(self, by: Name | Series | list[Name | Series], axis: Axis = 0, as_index: bool = True, dropna: bool = True) -> SeriesGroupBy: ...
    def resample(self, rule: str_type, closed: str_type | None = None, label: str_type | None = None, on: Series | None = None) -> SeriesResampler: ...
    def __getitem__(self, key: Any) -> Any: ...
    def __getattr__(self, item: str_type) -> Any: ...
    def __dir__(self) -> Iterable[str_type]: ...
    def __iter__(self) -> None: ...
    def __class_getitem__(cls, params: Any) -> type[SeriesType]: ...

def unpack_scalar(sdf: SparkDataFrame) -> Any: ...
@overload
def first_series(df: DataFrame) -> Series: ...
@overload
def first_series(df: pd.DataFrame) -> pd.Series: ...

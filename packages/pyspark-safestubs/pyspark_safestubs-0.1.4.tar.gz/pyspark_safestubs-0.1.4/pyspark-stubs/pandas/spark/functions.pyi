from pyspark import SparkContext as SparkContext
from pyspark.sql.column import Column as Column
from pyspark.sql.utils import is_remote as is_remote

def product(col: Column, dropna: bool) -> Column: ...
def stddev(col: Column, ddof: int) -> Column: ...
def var(col: Column, ddof: int) -> Column: ...
def skew(col: Column) -> Column: ...
def kurt(col: Column) -> Column: ...
def mode(col: Column, dropna: bool) -> Column: ...
def covar(col1: Column, col2: Column, ddof: int) -> Column: ...
def repeat(col: Column, n: int | Column) -> Column: ...
def ewm(col: Column, alpha: float, ignore_na: bool) -> Column: ...
def last_non_null(col: Column) -> Column: ...
def null_index(col: Column) -> Column: ...
def timestampdiff(unit: str, start: Column, end: Column) -> Column: ...

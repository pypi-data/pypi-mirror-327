import pandas as pd
from _typeshed import Incomplete
from datetime import tzinfo
from pandas.tseries.offsets import DateOffset
from pyspark.pandas._typing import Axis, Dtype, Name
from pyspark.pandas.frame import DataFrame
from pyspark.pandas.indexes import DatetimeIndex, Index, TimedeltaIndex
from pyspark.pandas.series import Series
from pyspark.sql.types import StructType
from typing import Any, Callable

__all__ = ['from_pandas', 'range', 'read_csv', 'read_delta', 'read_table', 'read_spark_io', 'read_parquet', 'read_clipboard', 'read_excel', 'read_html', 'to_datetime', 'date_range', 'to_timedelta', 'timedelta_range', 'get_dummies', 'concat', 'melt', 'isna', 'isnull', 'notna', 'notnull', 'read_sql_table', 'read_sql_query', 'read_sql', 'read_json', 'merge', 'merge_asof', 'to_numeric', 'broadcast', 'read_orc']

def from_pandas(pobj: pd.DataFrame | pd.Series | pd.Index) -> Series | DataFrame | Index: ...
def range(start: int, end: int | None = None, step: int = 1, num_partitions: int | None = None) -> DataFrame: ...
def read_csv(path: str | list[str], sep: str = ',', header: str | int | None = 'infer', names: str | list[str] | None = None, index_col: str | list[str] | None = None, usecols: list[int] | list[str] | Callable[[str], bool] | None = None, squeeze: bool = False, mangle_dupe_cols: bool = True, dtype: str | Dtype | dict[str, str | Dtype] | None = None, nrows: int | None = None, parse_dates: bool = False, quotechar: str | None = None, escapechar: str | None = None, comment: str | None = None, encoding: str | None = None, **options: Any) -> DataFrame | Series: ...
def read_json(path: str, lines: bool = True, index_col: str | list[str] | None = None, **options: Any) -> DataFrame: ...
def read_delta(path: str, version: str | None = None, timestamp: str | None = None, index_col: str | list[str] | None = None, **options: Any) -> DataFrame: ...
def read_table(name: str, index_col: str | list[str] | None = None) -> DataFrame: ...
def read_spark_io(path: str | None = None, format: str | None = None, schema: str | StructType = None, index_col: str | list[str] | None = None, **options: Any) -> DataFrame: ...
def read_parquet(path: str, columns: list[str] | None = None, index_col: list[str] | None = None, pandas_metadata: bool = False, **options: Any) -> DataFrame: ...
def read_clipboard(sep: str = '\\s+', **kwargs: Any) -> DataFrame: ...
def read_excel(io: str | Any, sheet_name: str | int | list[str | int] | None = 0, header: int | list[int] = 0, names: list | None = None, index_col: list[int] | None = None, usecols: int | str | list[int | str] | Callable[[str], bool] | None = None, squeeze: bool = False, dtype: dict[str, str | Dtype] | None = None, engine: str | None = None, converters: dict | None = None, true_values: Any | None = None, false_values: Any | None = None, skiprows: int | list[int] | None = None, nrows: int | None = None, na_values: Any | None = None, keep_default_na: bool = True, verbose: bool = False, parse_dates: bool | list | dict = False, date_parser: Callable | None = None, thousands: str | None = None, comment: str | None = None, skipfooter: int = 0, convert_float: bool = True, mangle_dupe_cols: bool = True, **kwds: Any) -> DataFrame | Series | dict[str, DataFrame | Series]: ...
def read_html(io: str | Any, match: str = '.+', flavor: str | None = None, header: int | list[int] | None = None, index_col: int | list[int] | None = None, skiprows: int | list[int] | slice | None = None, attrs: dict[str, str] | None = None, parse_dates: bool = False, thousands: str = ',', encoding: str | None = None, decimal: str = '.', converters: dict | None = None, na_values: Any | None = None, keep_default_na: bool = True, displayed_only: bool = True) -> list[DataFrame]: ...
def read_sql_table(table_name: str, con: str, schema: str | None = None, index_col: str | list[str] | None = None, columns: str | list[str] | None = None, **options: Any) -> DataFrame: ...
def read_sql_query(sql: str, con: str, index_col: str | list[str] | None = None, **options: Any) -> DataFrame: ...
def read_sql(sql: str, con: str, index_col: str | list[str] | None = None, columns: str | list[str] | None = None, **options: Any) -> DataFrame: ...
def to_datetime(arg, errors: str = 'raise', format: Incomplete | None = None, unit: Incomplete | None = None, infer_datetime_format: bool = False, origin: str = 'unix'): ...
def date_range(start: str | Any = None, end: str | Any = None, periods: int | None = None, freq: str | DateOffset | None = None, tz: str | tzinfo | None = None, normalize: bool = False, name: str | None = None, closed: str | None = None, **kwargs: Any) -> DatetimeIndex: ...
def to_timedelta(arg, unit: Incomplete | None = None, errors: str = 'raise'): ...
def timedelta_range(start: str | Any = None, end: str | Any = None, periods: int | None = None, freq: str | DateOffset | None = None, name: str | None = None, closed: str | None = None) -> TimedeltaIndex: ...
def get_dummies(data: DataFrame | Series, prefix: str | list[str] | dict[str, str] | None = None, prefix_sep: str = '_', dummy_na: bool = False, columns: Name | list[Name] | None = None, sparse: bool = False, drop_first: bool = False, dtype: str | Dtype | None = None) -> DataFrame: ...
def concat(objs: list[DataFrame | Series], axis: Axis = 0, join: str = 'outer', ignore_index: bool = False, sort: bool = False) -> Series | DataFrame: ...
def melt(frame: DataFrame, id_vars: Name | list[Name] | None = None, value_vars: Name | list[Name] | None = None, var_name: str | list[str] | None = None, value_name: str = 'value') -> DataFrame: ...
def isna(obj): ...
isnull = isna

def notna(obj): ...
notnull = notna

def merge(obj: DataFrame, right: DataFrame, how: str = 'inner', on: Name | list[Name] | None = None, left_on: Name | list[Name] | None = None, right_on: Name | list[Name] | None = None, left_index: bool = False, right_index: bool = False, suffixes: tuple[str, str] = ('_x', '_y')) -> DataFrame: ...
def merge_asof(left: DataFrame | Series, right: DataFrame | Series, on: Name | None = None, left_on: Name | None = None, right_on: Name | None = None, left_index: bool = False, right_index: bool = False, by: Name | list[Name] | None = None, left_by: Name | list[Name] | None = None, right_by: Name | list[Name] | None = None, suffixes: tuple[str, str] = ('_x', '_y'), tolerance: Any | None = None, allow_exact_matches: bool = True, direction: str = 'backward') -> DataFrame: ...
def to_numeric(arg, errors: str = 'raise'): ...
def broadcast(obj: DataFrame) -> DataFrame: ...
def read_orc(path: str, columns: list[str] | None = None, index_col: str | list[str] | None = None, **options: Any) -> DataFrame: ...

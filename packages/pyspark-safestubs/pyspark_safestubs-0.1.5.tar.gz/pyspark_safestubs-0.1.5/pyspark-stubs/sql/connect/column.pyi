import pyspark.sql.connect.proto as proto
from _typeshed import Incomplete
from pyspark.errors import PySparkAttributeError as PySparkAttributeError, PySparkTypeError as PySparkTypeError, PySparkValueError as PySparkValueError
from pyspark.sql.connect._typing import DateTimeLiteral as DateTimeLiteral, DecimalLiteral as DecimalLiteral, LiteralType as LiteralType
from pyspark.sql.connect.client import SparkConnectClient as SparkConnectClient
from pyspark.sql.connect.expressions import CaseWhen as CaseWhen, CastExpression as CastExpression, DropField as DropField, Expression as Expression, LiteralExpression as LiteralExpression, SortOrder as SortOrder, UnresolvedExtractValue as UnresolvedExtractValue, UnresolvedFunction as UnresolvedFunction, WindowExpression as WindowExpression, WithField as WithField
from pyspark.sql.connect.utils import check_dependencies as check_dependencies
from pyspark.sql.connect.window import WindowSpec as WindowSpec
from pyspark.sql.types import DataType as DataType
from typing import Any, overload

class Column:
    def __init__(self, expr: Expression) -> None: ...
    __gt__: Incomplete
    __lt__: Incomplete
    __add__: Incomplete
    __sub__: Incomplete
    __mul__: Incomplete
    __div__: Incomplete
    __truediv__: Incomplete
    __mod__: Incomplete
    __radd__: Incomplete
    __rsub__: Incomplete
    __rmul__: Incomplete
    __rdiv__: Incomplete
    __rtruediv__: Incomplete
    __rmod__: Incomplete
    __pow__: Incomplete
    __rpow__: Incomplete
    __ge__: Incomplete
    __le__: Incomplete
    eqNullSafe: Incomplete
    __neg__: Incomplete
    __and__: Incomplete
    __or__: Incomplete
    __invert__: Incomplete
    __rand__: Incomplete
    __ror__: Incomplete
    def __contains__(self, item: Any) -> None: ...
    bitwiseOR: Incomplete
    bitwiseAND: Incomplete
    bitwiseXOR: Incomplete
    isNull: Incomplete
    isNotNull: Incomplete
    def __ne__(self, other: Any) -> Column: ...
    contains: Incomplete
    startswith: Incomplete
    endswith: Incomplete
    def when(self, condition: Column, value: Any) -> Column: ...
    def otherwise(self, value: Any) -> Column: ...
    like: Incomplete
    rlike: Incomplete
    ilike: Incomplete
    @overload
    def substr(self, startPos: int, length: int) -> Column: ...
    @overload
    def substr(self, startPos: Column, length: Column) -> Column: ...
    def __eq__(self, other: Any) -> Column: ...
    def to_plan(self, session: SparkConnectClient) -> proto.Expression: ...
    def alias(self, *alias: str, **kwargs: Any) -> Column: ...
    name = alias
    def asc(self) -> Column: ...
    def asc_nulls_first(self) -> Column: ...
    def asc_nulls_last(self) -> Column: ...
    def desc(self) -> Column: ...
    def desc_nulls_first(self) -> Column: ...
    def desc_nulls_last(self) -> Column: ...
    def cast(self, dataType: DataType | str) -> Column: ...
    astype = cast
    def over(self, window: WindowSpec) -> Column: ...
    def isin(self, *cols: Any) -> Column: ...
    def between(self, lowerBound: Column | LiteralType | DateTimeLiteral | DecimalLiteral, upperBound: Column | LiteralType | DateTimeLiteral | DecimalLiteral) -> Column: ...
    def getItem(self, key: Any) -> Column: ...
    def getField(self, name: Any) -> Column: ...
    def withField(self, fieldName: str, col: Column) -> Column: ...
    def dropFields(self, *fieldNames: str) -> Column: ...
    def __getattr__(self, item: Any) -> Column: ...
    def __getitem__(self, k: Any) -> Column: ...
    def __iter__(self) -> None: ...
    def __nonzero__(self) -> None: ...
    __bool__ = __nonzero__

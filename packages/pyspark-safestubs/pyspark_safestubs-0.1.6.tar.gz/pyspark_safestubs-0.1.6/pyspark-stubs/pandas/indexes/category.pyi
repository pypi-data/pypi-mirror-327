import pandas as pd
from _typeshed import Incomplete
from pandas.api.types import CategoricalDtype
from pyspark.pandas.indexes.base import Index as Index
from pyspark.pandas.internal import InternalField as InternalField
from pyspark.pandas.series import Series as Series
from pyspark.sql.types import StructField as StructField
from typing import Any, Callable

class CategoricalIndex(Index):
    def __new__(cls, data: Incomplete | None = None, categories: Incomplete | None = None, ordered: Incomplete | None = None, dtype: Incomplete | None = None, copy: bool = False, name: Incomplete | None = None): ...
    @property
    def dtype(self) -> CategoricalDtype: ...
    @property
    def codes(self) -> Index: ...
    @property
    def categories(self) -> pd.Index: ...
    @categories.setter
    def categories(self, categories: pd.Index | list) -> None: ...
    @property
    def ordered(self) -> bool: ...
    def add_categories(self, new_categories: pd.Index | Any | list, inplace: bool = False) -> CategoricalIndex | None: ...
    def as_ordered(self, inplace: bool = False) -> CategoricalIndex | None: ...
    def as_unordered(self, inplace: bool = False) -> CategoricalIndex | None: ...
    def remove_categories(self, removals: pd.Index | Any | list, inplace: bool = False) -> CategoricalIndex | None: ...
    def remove_unused_categories(self, inplace: bool = False) -> CategoricalIndex | None: ...
    def rename_categories(self, new_categories: list | dict | Callable, inplace: bool = False) -> CategoricalIndex | None: ...
    def reorder_categories(self, new_categories: pd.Index | Any | list, ordered: bool | None = None, inplace: bool = False) -> CategoricalIndex | None: ...
    def set_categories(self, new_categories: pd.Index | list, ordered: bool | None = None, rename: bool = False, inplace: bool = False) -> CategoricalIndex | None: ...
    def map(self, mapper: dict | Callable[[Any], Any] | pd.Series) -> Index: ...
    def all(self, *args, **kwargs) -> None: ...
